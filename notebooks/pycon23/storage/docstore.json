{"docstore/data": {"a67ac7a9-ff7d-4564-8680-7cd97318c105": {"__data__": {"id_": "a67ac7a9-ff7d-4564-8680-7cd97318c105", "embedding": null, "metadata": {"Section": "Data Science, AI & ML", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "Taking a Multilingual Conversational Engine to Production: Theory to Reality", "speaker": "karthikavijayanexpts"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "601a0e2a7ea5129035608f3e8d5d8495a274d9327c73c05c597ec4c446e1f321", "text": "\n\nDescription:\nWe built a multilingual virtual assistant to cover a diverse customer-base in a country like India, where more than a 100 languages are spoken. The conversational engine is designed to engage with users in several languages, at least in the order of tens. Solving this problem was non-trivial. There were learnings from different challenges while deploying this engine to production. In this talk, we will discuss the development and deployment of a multilingual virtual assistant for Indian languages using a Python-based framework, while crafting the assistants' responses with dynamic data integration (a) for user's queries and (b) at assistant's own initiation.\nWe designed a language-agnostic natural language understanding (NLU) pipeline for the conversational engine, using which the virtual assistant 'understands' customer queries in multiple languages. The dialog flow for the conversational engine was designed by envisioning potential engagement scenarios in customer support. Custom responses from the engine are crafted in multiple forms, with integration of user-specific systems of records. This enables the virtual assistant to \u2018respond\u2019 to customer queries with an evolutionary conversational flow in a personalized manner. Our efforts in developing this multilingual virtual assistant have resulted in 97% NLU accuracy in benchmark measurements, and the deployed version attracted 93% of 'Happy' feedback rating from customers expressing their satisfaction.\nOutline of the talk (tentative)\n\nIntroduction (2 mins) \nHow the conversational assistant understands queries in multiple languages (6 mins) \nHow the conversational assistant generates custom responses (4 mins) \nChallenges in going to production : examples from real-life scenarios (5 mins) \nSolutions for addressing these challenges and monitoring on prod (7 mins)\nQ/A (5 mins)\n\nTakeaways\n\nLearn about a language-agnostic multilingual NLU process pipeline\nInsights into data-conditions that aid multilingual conversational engines \nUnderstand challenges in deploying such an engine in production \nAddressing dynamic nature of dialogue flow and personalized response generation \nPeriodic monitoring and feedback\n\n\n\n\nPrerequisites:\nBasic understanding of machine learning\n\n\n\nVideo URL:\nhttps://drive.google.com/file/d/1TsSV3Idx3rYUMnulfKgJr1m9Aq1UrsGe/view?usp=drive_link\n\n\n\nSpeaker Info:\nSpeaker bio -1\nDr. Karthika Vijayan is a Solution Consultant at Sahaj Software. She has been conducting research in the field of conversational AI with voice and text data for almost a decade. Her research has been published in several journals and presented at various international conferences. Her expertise includes creating customized solutions for real-world business problems by designing composite machine learning pipelines.\nSpeaker bio -2\nShruti Dhavalikar is a skilled Data Scientist with over 4 years of experience in the field, currently working as a Solution Consultant at Sahaj Software in Pune, India. With a deep passion for data science and a strong understanding of data analysis, she thrives on designing models that build valuable business insights from data. She has successfully delivered end-to-end product cycles under Agile methodology, showcasing her ability to handle diverse tech stacks and ensure scalable, clean, and robust design. Passionate about her work, she actively contributes to research projects and tries to stay at the forefront of advancements in the field. She has published research papers at international conferences.\n\n\n\nSpeaker Links:\nSpeaker -1 (Karthika Vijayan) \nProfile links and previous talk links -\n\nhttps://scholar.google.com/citations?user=fJp6O0UAAAAJ&hl=en\nhttps://www.linkedin.com/in/karthika-vijayan/\nhttps://www.researchgate.net/profile/Karthika-Vijayan\nhttps://www.youtube.com/watch?v=kphYc_lvKIk&list=PLkPaq00oPRfzz9O4q06rOL2dHCEX7PQwU&index=18\nhttps://www.youtube.com/watch?v=gvJhtBdmUi8&t=897s\nhttps://www.youtube.com/watch?v=fTlBvqHfbRI\n\nSpeaker -2 (Shruti Dhavalikar)\nProfile links -\n\nhttps://www.linkedin.com/in/shruti-dhavalikar-83514615a\nhttps://scholar.google.com/citations?hl=en&pli=1&user=5029f7QAAAAJ\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "01bd0569-e9a1-4826-9941-4a97946c9576": {"__data__": {"id_": "01bd0569-e9a1-4826-9941-4a97946c9576", "embedding": null, "metadata": {"Section": "Core Python", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "LPython: Novel, Fast, Retargetable Python Compiler", "speaker": "Ubaid Shaikh (~ubaid7)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b0c8111dbac9a4867ef701705dbcc7da3d1ab5e701a6b7baef09aded41ed2bea", "text": "\n\nDescription:\nAbstract\nPython has long been favored for its simplicity, productivity, and versatile ecosystem. However, when it comes to performance-critical tasks and numerical computing, the trade-off between ease of use and execution speed has been a challenge. Enter LPython, an open-source Python compiler that revolutionizes the way we harness Python's power.\nDescription\nIn this talk, we will explore the fascinating world of LPython, a cutting-edge Python compiler that leverages type annotations to produce optimized machine code. The session will delve into the unique features and benefits of LPython, as well as demonstrate its seamless interoperability with CPython.\nOutline of the talk:\n\nIntroduction (2 minutes)\n\nWelcome and brief introduction of the speaker.\nOverview of the talk's agenda and what attendees can expect to learn.\n\nWhat is LPython? (2 minutes)\n\nExplaining LPython as an open-source Python compiler.\nHow it compiles type-annotated Python code into optimized machine code.\nDifferentiating LPython from traditional Python interpreters.\n\nAbstract Syntax Tree (AST) and Abstract Semantic Representation (ASR) (2 minutes)\n\nExploring the concept of AST and ASR and their role in LPython.\nUnderstanding how ASR facilitates independent optimizations (using ASR passes) and enhances compiler capabilities.\n\nBackends (4 minutes)\n\nUnderstanding the available backends (LLVM, C, C++, WASM) in LPython.\n\nOnline Demo (4 minutes)\n\nLive demo of code compilation using LPython in browser.\nShowcase AST, ASR, C, WAT (WebAssembly Text Format) output tabs on the website.\n\nAhead-of-Time (AoT) and Just-In-Time (JIT) Compilation (2 minutes)\n\nDifferentiating between AoT and JIT compilation in LPython.\nExplaining how AoT generates binary output and JIT translates code during runtime.\n\nInteroperability with CPython (2 minutes)\n\nDiscussing how LPython allows seamless integration with CPython libraries.\nShowcasing the @pythoncall decorator and its practical applications (Matplotlib for graphs and Mandelbrot Set).\n\nSpeed and Performance Benchmarks (2 minutes)\n\nPresenting performance benchmarks comparing LPython against C++.\nShowcasing LPython's efficiency in numerical and array-oriented computations.\n\nConclusion and Takeaways (2 minutes)\n\nSummarizing the key points covered in the talk.\nEncouraging attendees to embrace LPython for their projects.\n\nQ&A Session (5 minutes)\n\nAllowing attendees to ask questions related to LPython, its features, and practical implementations.\nEngaging in discussions and providing clarifications as needed.\n\nClosing Remarks (1 minute)\n\nExpressing gratitude to the audience for their participation.\nSharing contact information and additional resources for further exploration.\n\n\nExpected Takeaways:\nAttendees will walk away with a comprehensive understanding of LPython's capabilities, its role in enhancing Python's performance, and the practical steps to integrate LPython into their projects. They will be inspired to leverage the strengths of LPython for blazingly fast computations without sacrificing Python's user-friendly features.\n\n\n\nPrerequisites:\nBasic Python experience would be helpful.\n\n\n\nContent URLs: \nLPython: https://lpython.org\nGitHub: https://github.com/lcompilers/lpython\nBlog: LPython: Novel, Fast, Retargetable Python Compiler\nSlides: Presentation Slides\n\n\n\nSpeaker Info:\nUbaid Shaikh received his B.Tech degree in Computer Science and Engineering from Indian Institute of Technology Indore, India. \nHe is currently a Compiler Developer at GSI Technology working on LPython and LFortran Compilers. In the past, he has interned at Development Bank of Singapore (DBS Bank) and has been a Google Summer of Code (GSoC) Fellow.\n\n\n\nSpeaker Links:\nGitHub: https://github.com/Shaikh-Ubaid\nEmail: shaikhubaid769@gmail.com\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "89c72d08-a8b8-4b3a-a612-095bc14ec5db": {"__data__": {"id_": "89c72d08-a8b8-4b3a-a612-095bc14ec5db", "embedding": null, "metadata": {"Section": "Game Design and 3D Modelling", "Type": "Talks", "Target Audience": "Beginner", "Last Updated": "12 Sep, 2023", "title": "Python-powered Game Design and 3D Modelling: Unleashing Creativity and Immersion", "speaker": "Bhawna (~ConnectBhawna)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c72511ac7457e3cf3898809b021e7065d25821de72a959c87c74f1fa0475ebd2", "text": "\n\nDescription:\nIn recent years, the intersection of game design, 3D modelling, and immersive technologies has opened up exciting avenues for developers and enthusiasts alike. This proposal aims to explore the potential of Python in empowering game design and 3D modelling processes while incorporating augmented reality (AR) and virtual reality (VR) elements. By leveraging Python's versatility and extensive libraries, attendees will discover how to create and manipulate 3D models, apply principles of game design, and infuse immersive experiences into their projects.\nOutline:\n1. Introduction (5 minutes)\na. Overview of the proposal's objectives and scope\nb. Importance of Python in game design and 3D modelling\n2. Python for 3D Modelling (15 minutes)\na. Introduction to popular Python libraries/frameworks for 3D modelling (e.g., Pygame, Panda3D)\nb. Demonstrations of 3D model creation and manipulation using Python code\nc. Tips and best practices for efficient 3D modelling workflows in Python\n3. Principles of Game Design (15 minutes)\na. Overview of core game design principles and methodologies\nb. Integrating Python into the game design process\nc. Hands-on exercises showcasing Python's role in game design\n4. Augmented Reality (AR) and Virtual Reality (VR) with Python (20 minutes)\na. Introduction to AR/VR concepts and applications\nb. Overview of Python libraries for AR/VR development (e.g., Pygame, Pyglet, OpenCV)\nc. Live coding session to create an AR/VR experience using Python\n5. Enhancing Immersion: Python's Role (15 minutes)\na. Exploring techniques to enhance immersion in games using Python\nb. Incorporating audio, physics, and AI elements with Python\nc. Real-world examples and case studies\n6. Q&A Session and Wrap-up (10 minutes)\na. Answering questions and addressing concerns\nb. Recap of key takeaways from the session\nc. Providing additional resources for further learning\n\n\n\nPrerequisites:\nThis topic is suitable for developers, programmers, students, and enthusiasts interested in game design, 3D modelling, and immersive technologies. Attendees should have a basic understanding of Python programming concepts.\n\n\n\nSpeaker Info:\nSoftware Intern@monado | LFX'23 @project_harbor |  @GithubCampus Expert \u26f3 | Founder @SheBuildsHack | @MLHacks Fellow | 20 x Hackathon Winner \ud83c\udfc6\n\n\n\nSpeaker Links:\nFor my previous work you can refer this(open source /projects ) : https://bhawna-resume.vercel.app/\nSpeaking PPT :\n=>  In Recent SheBuilds Meetup : https://www.canva.com/design/DAFlWF_7N6I/zHEhuatBtfxyfKZyhdrI2A/edit?utm_content=DAFlWF_7N6I&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton\n=> Youtube channel for Content : https://youtu.be/IHSd1ryA4SY\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "12e7972e-a0a0-4eb5-bd40-53214902f2fd": {"__data__": {"id_": "12e7972e-a0a0-4eb5-bd40-53214902f2fd", "embedding": null, "metadata": {"Section": "Core Python", "Type": "Talks", "Target Audience": "Beginner", "Last Updated": "12 Sep, 2023", "title": "What's the mojo behind Mojo", "speaker": "kam"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "390c1d48fc02712ed0361bdc24d4fa01d269703b0aa2c9d56c9e9eba7785f70d", "text": "\n\nDescription:\nWe've all heard it before: Python is slow.\nMojo, a brand new programming language, aims to fix just that. Mojo combines the usability of Python with the speed of C. \nThe result? Mojo can be up to 35,000X faster than Python.\nMojo is a superset of Python, just like Typescript is to Javascript. It's built on top of next-gen compiler technologies (MLIR) that unlock significant performance gains. So code written in Python can achieve performance on par with C++.\nMojo doesn\u2019t just look and feel like Python. It gives you access to the full Python ecosystem and existing Python code. Jeremy Howard said that Mojo \"may be the biggest programming language advance in decades.\"\nIn my talk, I will speak in depth about the following topics -\n\nWhat's Mojo?\nWhat makes it fast?\nWhat are possible use cases?\nIs deployment easier than Python?\nHow's it different from Numba or Cython?\nAre there new datatypes and keywords in Mojo?\nWhat are the tradeoffs of using Mojo?\nDemo with a Mojo notebook\n\n\n\n\nPrerequisites:\nA basic understanding of Python is good to have.\n\n\n\nSpeaker Info:\nKamran is a software engineer at Microsoft and has been building software for almost a decade. His current area of interest is distributed systems and he's a Certified Solutions Architect.  He shares his thoughts on Medium, speaks at community events and answers questions on StackOverflow. \nWhen he's not working, you'll find him reading a book or going on a long drive.\n\n\n\nSpeaker Links:\n\nLinkedIn: https://www.linkedin.com/in/kamahmad/ \nSpoke about immutable databases at HydPy Meetup: https://twitter.com/hydPython/status/1628965087959728128?s=20\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9ac92011-42cb-4180-af2c-5a6714082acc": {"__data__": {"id_": "9ac92011-42cb-4180-af2c-5a6714082acc", "embedding": null, "metadata": {"Section": "Web & App development", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "14 Sep, 2023", "title": "Data Encoding Formats: A Comparison of Text-Based and Binary Encoding", "speaker": "Priyadarshan  Patil (~priyadarshan)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "0f7acb9e77cbcbab910098c483dc0294ac4e7b7889d9a284e3f529e99657ff01", "text": "\n\nDescription:\nText-Based Encoding (translation of in-memory data representation to a byte sequence) formats are ubiquitous and are known to everyone namely JSON, XML, and CSV. JSON and XML formats are widely used for API and message-based communication but have poor support for running different versions of applications at the same time apart from their average performance in storage and communication. Alternative binary encoding formats exist namely Avro, Thrift, and Protobuf but there is little awareness about them. These formats provide superior support on application forward and backward compatibility requirements and improved performance on storage and communication. But they also come with their own set of overheads and are not always the best fit for all our application implementation use cases.  The talk aims to sensitize techies on these different types of encoding formats, their data encoding strategies, the impact on the performance of storage, and data communication speeds and application compatibility issues. To validate the above points the results of benchmarking these encoding formats for speed and storage metrics using a Python Based Application Performance Monitoring tool - Locust would be shared. Armed with this knowledge choosing the right encoding formats in the context of the use cases would be easy\n\n\n\nPrerequisites:\n\nJSON and XML Formats\nWhat Schemas are?\n\n\n\n\nContent URLs: \nSlides\n\n\n\nSpeaker Info:\nPriyadarshan works as Solution Consultant at Sahaj.ai. He has 16 years of Software Engineering experience focussed on Tech Consulting and implementation and building strong technology teams. He has worked on Distributed systems, and traditional monolith platforms and built products on top of Eclipse Platform. He has diverse experience in Software Engineering - building tech platforms, delivery management, customer relationship management, and presales. At Sahaj, he is learning the art of building technology platforms with extreme programming practice and working in high-trust and High accountability technology teams. He is also helping Sahaj bootstrap its delivery center in Hyderabad.\n\n\n\nSpeaker Links:\nSpeaker Links:\n - Link 1\n - Link 2\nBlog Links:\n - Blog#1\n - Blog#2 \n - Blog#3\n - Blog#4\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "906c31f0-3c77-4734-92a4-e021d33c90f9": {"__data__": {"id_": "906c31f0-3c77-4734-92a4-e021d33c90f9", "embedding": null, "metadata": {"Section": "Data Science, AI & ML", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "OpenAI Whisper and it\u2019s amazing power to do fine-tuning demonstrated on my mother-tongue", "speaker": "Kurian Benoy (~kurianbenoy)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "5d467a392e6058cd8e2f208fccd1a771c5522a9b66506fadb5265957ce30563c", "text": "\n\nDescription:\nThe core of the talk covers how we can fine tune a whisper model. I will specifically talk about fine tuning whisper to achieve state of the art results in a low resource language like Malayalam. We have got great results on fine-tuning on Malayalam whisper model.  The original model weights of Whisper was reported with a  WER of 108% and we were able to fine tune to reach a WER of close to 10%(approx 90 percentage accuracy) in CommonVoice 11 Malayalam subset and even 1% WER in MSC dataset.\nTalk Outline:\n\nWhat is OpenAI Whisper?\nFeatures of OpenAI Whisper \nWhat is Fine-tuning and how to fine-tune Whisper?\nAbout my mother tongue\nMethodology of benchmarking whisper models\nResults on benchmarking Whisper model\nFuture Ideas & Conclusion\n\n\n\n\nPrerequisites:\n\nAny developer with 1 years experience, they needn't have any prior ML experience. I will try to demystify any jargons during my talk that's why I am saying no experience is needed in ML.\nLot of interest in your own mother-tongue is always appreciated.\n\n\n\n\nContent URLs: \nSlides\nGithub project: \n\nhttps://github.com/kurianbenoy/malayalam_asr_benchmarking\n\nBenchmarking results: \n\nhttps://huggingface.co/datasets/kurianbenoy/malayalam_msc_benchmarking/tree/main\nhttps://huggingface.co/datasets/kurianbenoy/malayalam_common_voice_benchmarking\n\n\n\n\nSpeaker Info:\nKurian is a Team Lead and AI Engineer working in sentient.io, a fast-paced startup based in Singapore. I have multiple years of experience in Python and Machine learning experience, where I am now looking more into the MLOPs side. I have contributed to various open source organizations like Keras, DVC, HuggingFace, fast.ai, Swathanthra Malayalam Computing, CloudCV etc.\nMore details about my previous talks can be found in below link.\n\n\n\nSpeaker Links:\n\nPrevious Talks\nBlog\nLinkedIn\nTwitter\nGithub\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b77e7671-7eb9-473e-961a-eaff94e9d8d2": {"__data__": {"id_": "b77e7671-7eb9-473e-961a-eaff94e9d8d2", "embedding": null, "metadata": {"Section": "Networking and Security", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "Securing your python applications and network using Zero Trust Security", "speaker": "Srijan R Shetty (~srijanshetty)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "9d0ece76166c4d3359b518a34441dcc80954ad1c6d5195ca255a7d1d18294248", "text": "\n\nDescription:\nSecuring applications is hard.\nAWS Security Groups, Firewalls, iptables don't make it any easier.\nIt's common to hear terms like Zero Trust, Mesh VPNs, SD-WAN being thrown around in the context of modern DevOps but it's hard to keep upto speed with them or even start using them in the wild due to the lack of resources.\nFret not, in this talk we'll cover Zero Trust from first principles and go through examples of creating secure by default production environments using Fast API. We'll understand what the noise about mesh VPNs and why DevOps can't stop raving about them. In particular we would look at TailScale which is an excellent way to get started on the journey of secure, encrypted production environments with fine grained access controls.\nLayout of the Talk\n- Initial Setup of TailScale (5 minutes)\n- Encrypted secure connections to redis from python (3 minutes)\n- ACLs & port mappings for your team (3 minutes)\n- Secure SSH over mesh VPNs (2 minutes)\n- Hosting Fast API securely with nginx, self hosted certificates (7 minutes)\n- Share local Fast API using TailScale funnel (5 minutes)\n- Securing connections to Postgres with pgproxy (Optional)\n\n\n\nPrerequisites:\nA basic understanding of python and know how of how to use a terminal to run commands.\n\n\n\nSpeaker Info:\nSrijan R Shetty is currently the cofounder and CTO of Fuze and is an alumnus of IIT Kanpur, Computer Science Department. \nPreviously I co-founded Allround Club - an EdTech teaching kids extra curricular online which was backed Stellaris Venture Partners and Athera Venture Partners.\nI spent half a decade in Goldman Sachs building a HFT dark pool and running liquidity provisioning strategies for automated trading. I also managed a Central Risk Book at Goldman Sachs, hedging Delta and FX Risk.\nWith more than 15 years of experience writing code, I've worked as a full stack developer writing low latency code in C++, building backends in Nodejs, doing research in Python, systems programming in Python, creating picture perfect frontends in React/Angular/HTML, and architecting DevOps in AWS, Digital Ocean and Azure.\n\n\n\nSpeaker Links:\n\nGitHub\n\nTwitter\nLinkedIn\nBlog\nTalks/Podcasts:\n\nCEO Talks: https://www.youtube.com/watch?v=T2zmczhhQI4\nRocket Health: https://www.youtube.com/watch?v=tUbadxxXAtA&t=35s\n\n\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c6a835b2-6b3c-4573-be5b-e9ffe34bb693": {"__data__": {"id_": "c6a835b2-6b3c-4573-be5b-e9ffe34bb693", "embedding": null, "metadata": {"Section": "Web & App development", "Type": "Talks", "Target Audience": "Advanced", "Last Updated": "12 Sep, 2023", "title": "Harnessing the Power of Django StreamingHttpResponse for Efficient Web Streaming", "speaker": "Shivam Chaurasia (~tracebackerror)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "351eb1154c69af37896a943b6844fde51505b11602132c2cf701d1d9dad737fa", "text": "\n\nDescription:\nTitle: Harnessing the Power of Django StreamingHttpResponse for Efficient Web Streaming\nIntroduction:\nIn the world of web development, streaming data has become increasingly popular. Whether it's live video feeds, real-time analytics, or large file downloads, streaming allows for efficient and seamless transmission of data over the web. Django, a high-level Python web framework, provides a powerful tool called StreamingHttpResponse that enables developers to implement streaming functionalities with ease. In this blog post, we will explore the capabilities of Django StreamingHttpResponse and discuss how it can enhance your web applications.\nWhat is Django StreamingHttpResponse?\nDjango StreamingHttpResponse is a class-based response that streams content to the client in chunks rather than waiting for the entire response to be generated. It allows you to iterate over a generator function or any other iterable, sending chunks of data to the client as they become available. This is particularly useful when dealing with large datasets or long-running processes, as it avoids buffering the entire response in memory.\nImplementing StreamingHttpResponse:\nTo use StreamingHttpResponse, you need to create a generator function or an iterable that generates the content you want to stream. Let's take a look at a simple example to illustrate the concept:\n```python\nfrom django.http import StreamingHttpResponse\n\ndef stream_data():\n    # Generate data in chunks\n    for i in range(10):\n        yield f\"Data chunk {i}\\n\"\n        # Simulate delay between chunks\n        time.sleep(1)\n\ndef streaming_view(request):\n    response = StreamingHttpResponse(stream_data())\n    response['Content-Type'] = 'text/plain'\n    return response\n```\n\nIn the code above, we define a generator function called stream_data() that yields data chunks. We then create a StreamingHttpResponse object by passing the generator function as the content argument. Finally, we set the appropriate Content-Type header and return the response.\nStreamingHttpResponse for streaming real-time stock market data\nLet's dive into a more sophisticated example of using Django's StreamingHttpResponse for streaming real-time stock market data to clients.\n```python\nfrom django.http import StreamingHttpResponse\nfrom channels.layers import get_channel_layer\nfrom asgiref.sync import async_to_sync\nimport json\nimport time\n\ndef generate_stock_data():\n    # Connect to a real-time stock data source (e.g., WebSocket, API)\n    # Iterate and yield stock data in chunks\n    while True:\n        stock_data = get_real_time_stock_data()\n        yield json.dumps(stock_data)\n        # Simulate delay between data updates\n        time.sleep(1)\n\ndef stream_stock_data(request):\n    channel_layer = get_channel_layer()\n    stream_name = \"stock_data_stream\"\n\n    def send_stock_data():\n        for stock_data in generate_stock_data():\n            async_to_sync(channel_layer.group_send)(stream_name, {\n                \"type\": \"stock_data_update\",\n                \"data\": stock_data\n            })\n            # Yield the data for streaming response as well\n            yield stock_data\n\n    response = StreamingHttpResponse(send_stock_data(), content_type=\"application/json\")\n\n    # Open a channel to stream data to clients via WebSocket or other streaming protocols\n    async_to_sync(channel_layer.group_add)(stream_name, request.channel_name)\n\n    def handle_disconnect():\n        # Cleanup and close the channel when the client disconnects\n        async_to_sync(channel_layer.group_discard)(stream_name, request.channel_name)\n\n    response.streaming_content.disconnect = handle_disconnect\n\n    return response\n```\n\nIn this example, we assume that you have set up Django Channels to handle WebSocket communication. Here's how the example works:\n\nWe define a generate_stock_data() function that connects to a real-time stock data source (e.g., WebSocket or API) and yields JSON-encoded stock data in chunks.\nIn the stream_stock_data() view function, we obtain the channel_layer to handle WebSocket communication.\nInside the send_stock_data() generator function, we iterate over the generated stock data and send it to the client via WebSocket using the group_send() method. We also yield the stock data for the streaming response.\nWe create a StreamingHttpResponse object with send_stock_data() as the content. We set the content type to \"application/json\" to indicate that the response contains JSON-encoded data.\nWe add the client's WebSocket channel to the stock_data_stream group using group_add(). This allows us to send stock data updates to all clients subscribed to the stream.\nWe define a handle_disconnect() function that gets called when the client disconnects. Inside this function, we remove the client's WebSocket channel from the stock_data_stream group using group_discard().\nWe assign the handle_disconnect() function to response.streaming_content.disconnect so that it gets called when the client disconnects.\n\nBy implementing this example, you can provide real-time stock data updates to clients, allowing them to receive and process the data as it becomes available. The use of Django's StreamingHttpResponse and Django Channels facilitates the seamless streaming of data and enhances the overall user experience in real-time stock market monitoring applications.\nEventStream in StreamingHttpResponse\nLet's combine the concepts of Event Stream and StreamingHttpResponse to create a real-time event stream using Django.\n```python\nfrom django.http import StreamingHttpResponse\n\ndef generate_events():\n    # Connect to an event source or database\n    # Retrieve and yield events in chunks\n    while True:\n        events = get_real_time_events()\n        for event in events:\n            yield f\"data: {event}\\n\\n\"\n        # Simulate delay between event updates\n        time.sleep(1)\n\ndef event_stream(request):\n    def stream_events():\n        for event in generate_events():\n            yield event\n\n    response = StreamingHttpResponse(stream_events(), content_type='text/event-stream')\n    response['Cache-Control'] = 'no-cache'\n    response['Transfer-Encoding'] = 'chunked'\n\n    return response\n```\n\nIn this example, we assume you have a source (e.g., event source, database) from which you can retrieve real-time events. Here's how the example works:\n\nWe define a generate_events() generator function that connects to the event source or database and yields events in chunks. Each event is formatted as an Event Stream line with a \"data\" field.\nInside the event_stream() view function, we define a stream_events() generator function that iterates over the generated events and yields them.\nWe create a StreamingHttpResponse object with stream_events() as the content and set the content type to \"text/event-stream\" to indicate that we are streaming an Event Stream.\nWe set the appropriate response headers: Cache-Control is set to \"no-cache\" to ensure that the response is not cached, and Transfer-Encoding is set to \"chunked\" to enable streaming.\nFinally, we return the StreamingHttpResponse object as the response.\n\nBy implementing this example, you can create a real-time event stream where clients can connect and receive event updates as they occur. This approach is particularly useful for applications such as real-time chat systems, live feeds, or activity streams where users need to be continuously informed about the latest events.\nAdvantages of StreamingHttpResponse:\n1. Memory Efficiency: StreamingHttpResponse streams data in chunks, which reduces the memory footprint compared to buffering the entire response. This makes it ideal for scenarios involving large datasets or files.\n\nImproved User Experience: Streaming responses provide a better user experience for long-running processes or when dealing with large files. Instead of waiting for the entire content to load, users can start consuming data as it becomes available.\nReal-Time Data Streaming: Django's StreamingHttpResponse enables real-time data streaming, making it suitable for applications like live video feeds, chat applications, or real-time analytics. Clients can receive data updates as soon as they are available.\nScalability: By avoiding the need to buffer the entire response, StreamingHttpResponse allows your application to handle multiple concurrent streaming requests more efficiently. This scalability is crucial for applications that serve a high volume of users or deal with heavy data processing.\n\nConsiderations and Best Practices:\nWhile Django's StreamingHttpResponse provides powerful streaming capabilities, there are some considerations and best practices to keep in mind:\n\nChunk Size: The size of each data chunk should be optimized based on your use case and the client's network conditions. Very small chunks may lead to inefficient data transmission, while excessively large chunks may result in delays or connection timeouts.\nCompression: If streaming large amounts of text-based data, enabling compression can significantly reduce the bandwidth requirements and improve overall performance. Django supports various compression options that can be applied to the response.\nWeb Server Compatibility: StreamingHttpResponse works best with web servers that support streaming, such as Gunicorn or uWSGI. Ensure that your chosen server is compatible with streaming responses to leverage the full benefits.\n\nConclusion:\nDjango StreamingHttpResponse is a powerful tool that empowers developers to efficiently implement streaming functionalities in their web applications. Whether you are dealing with large datasets, real-time data updates, or long-running processes, StreamingHttpResponse offers an elegant solution that optimizes memory usage and\nenhances user experience. By utilizing this feature, you can unlock the potential for scalable, real-time streaming in your Django projects, opening up a wide range of possibilities for innovative and interactive web applications.\n\n\n\nPrerequisites:\nDjango, Python, Streaming API, Event Streams\n\n\n\nContent URLs: \nhttps://dev.to/epam_india_python/harnessing-the-power-of-django-streaminghttpresponse-for-efficient-web-streaming-56jh\n\n\n\nSpeaker Info:\nSpeaker at Pyconf Hyd 2022\nhttps://www.linkedin.com/in/tracebackerror/\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "62a3d4a8-fea9-402f-87ff-a76c584bae25": {"__data__": {"id_": "62a3d4a8-fea9-402f-87ff-a76c584bae25", "embedding": null, "metadata": {"Section": "Data Science, AI & ML", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "Fine-Tuning Insights: Lessons from Experimenting with a Large Language Model on Slack Data", "speaker": "Samhita Alla (~samhita9)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c4016cd625d1b9ea4831901020a0d27e9bb27a60ee579fee2c8c7a23c2e6536c", "text": "\n\nDescription:\nLarge language models (LLMs) have taken the world by storm, revolutionizing our understanding and generation of human-like text. These models have demonstrated remarkable capabilities in various tasks, such as question-answering, chatbots, and even creative writing. However, adapting these models to specific use cases requires fine-tuning, which can initially be a challenging process to comprehend.\nIn this talk, attendees will delve into the intricacies of fine-tuning and explore different methods such as Low Rank Adapters (LoRA) and 8-bit fine-tuning to improve its efficiency. They will gain an understanding of the important factors to consider when fine-tuning a large language model. Furthermore, the audience will grasp the distinctions between fine-tuning and prompt engineering and develop insights into when to employ each approach.\nOne significant hurdle in fine-tuning these models is infrastructure. Despite the availability of cloud tools like Google Colab and consumer-grade GPUs, creating a suitable runtime environment for fine-tuning remains a major challenge. To address this, attendees will learn how to declaratively specify infrastructure with Flyte, empowering them to configure training jobs that effectively utilize the necessary compute resources for fine-tuning large language models on their own data.\nBy the end of the talk, attendees will have a solid understanding of the fine-tuning process, practical methods to enhance its efficiency, and the means to overcome infrastructure challenges. They will leave with valuable takeaways, ready to apply their knowledge and effectively adapt large language models to their specific use cases.\n\n\n\nPrerequisites:\nThe prerequisites for this talk are basic knowledge of Python and a general understanding of large language models.\n\n\n\nContent URLs: \nBlog post, GitHub repo\n\n\n\nSpeaker Info:\nSamhita is a developer advocate at Union.ai and a former tools developer at Oracle. She is passionate about software development and technical writing, and enjoys tackling challenges in the fields of growth and developer relations. In her free time, Samhita loves building machine learning and web applications. Committed to helping others succeed in the tech industry, Samhita has self-published a book navigating through the complex landscape of the field.\n\n\n\nSpeaker Links:\n\nPrevious talks: https://youtu.be/nXZHtaTnp14, https://youtu.be/9DMAkrM_gOA\nPersonal website\nGitHub\nLinkedIn\nTwitter\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "bd896639-527b-4fc2-aa5a-993720ef0fdd": {"__data__": {"id_": "bd896639-527b-4fc2-aa5a-993720ef0fdd", "embedding": null, "metadata": {"Section": "Concurrency", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "26 Sep, 2023", "title": "Lessons from optimising inter-process communication: Path to zero-copy", "speaker": "Kartheek S (~kartheek)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8029ef0bd1bbb61ba5e600b573188d302a61b09fb12e2ef82089b64dc16a37d8", "text": "\n\nDescription:\nThis talk aspires to be an insightful journey into the world of Inter-Process Communication (IPC) in Python, where we will take a neutral and unbiased look at various IPC techniques like sockets, shared memory and many more. The focus is on performance and efficiency over other things since the talk was inspired by a  batch processing workload where I was looking for ways to efficiently send large messages between processes. We'll delve into the trials and errors I encountered along the way.\nThroughout the session, we will benchmark and analyse different IPC methods, evaluating their strengths and shortcomings, and discussing their suitability in scenarios involving substantial data transfers. I hope that on attending this talk, you'll gain a deeper understanding of how to optimise your Python applications for IPC, especially when handling significant message sizes.\nThe talk is suitable for all Python developers, from beginners to seasoned professionals, as it equips you with the knowledge and tools to make informed IPC decisions for your future projects. So buckle up for the ride and I'll see you at the venue \ud83d\ude80\n\n\n\nPrerequisites:\n\nPython fundamentals\nIPC concepts (pipes, shared memory, sockets etc)\nFamiliarity with modules like concurrent.futures , multiprocessing and threading\nBasic OS concepts\n\n\n\n\nContent URLs: \nSlides: https://docs.google.com/presentation/d/1NQL73FQ595Kt5LIoM3Y2xlK4dou5b0cQPxYuGSuVM54/edit?usp=sharing\n\n\n\nSpeaker Info:\nMeet Kartheek, Head of Engineering at ScaleGenAI, with extensive experience in Python, Deep Learning, and Cloud/System Architecture. Holding a bachelor's degree in Information Technology, Kartheek has led various projects, including MLOps and highly available backend systems. His expertise, in Python, lies in concurrency and OOP, and he is currently focused on reducing Deep Learning model training time by 10-200x at ScaleGenAI.\n\n\n\nSpeaker Links:\n\nGithub\nLinkedIn\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d1fbc296-aebf-405e-8264-2a18b5e5b526": {"__data__": {"id_": "d1fbc296-aebf-405e-8264-2a18b5e5b526", "embedding": null, "metadata": {"Section": "Web & App development", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "The programmers guide to timestamps and timezones", "speaker": "Shrayas Rajagopal (~shrayas)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "862146e7b45ac456bc613b25c2d1098cc1676157bfcbbcb9fb78cf7239602a92", "text": "\n\nDescription:\nProblem\nThere are 24 different timezones in the world. And about 70 countries observe daylight savings times. As developers, we have to develop applications that are able to store timestamps generated from anywhere in the world, be it in the past or in the future. Additionally we also have to keep the code and database updated with any changes being made to the timezones and react to those accordingly. And timezone information changes quite often. For example, in 2022, we had 7 changes to the timezone database. \nMost of us when asked what timezone we are in, would respond with \u201cIST\u201d but you know that IST isn\u2019t a standardized timezone and can actually refer to Indian Standard Time, Israel Standard Time or Irish Standard Time. How do we handle this in the system?\nFor countries that observe DST (daylight savings time), when the clocks move forward, an entire hour is usually skipped and when they move backward, an hour occurs twice. So on a move forward day, an appointment scheduled for 3:00PM might actually be an invalid time. And on a move backward day, an appointment scheduled for 3:00PM might occur twice. How do we handle this in the system?\nOne quick answer, given that all times in the world can be converted into UTC, would be to say \u201cLet\u2019s just store everything in UTC\u201d. But there are problems in taking that approach too which we will discuss in the talk. \nJon Skeet, the author of the leading library to handle dates and times in the .NET world summarizes the date & time problem best by saying: \u201cEither you don\u2019t know it is difficult, or you know it is difficult but you assume that it is so difficult that you\u2019ll never ever get the right answer so you will just be OK with getting things occasionally wrong\u201d.\nBut there is one way by which we *can* tame the great date and time beasts - thorough understanding of the concepts.\nWe will start by looking at some of the most common questions that come up when dealing with parsing, storing and interacting with dates and times:\n\nWhat are timezones?\nWhat is daylight savings time?\nHow do I store timestamps in the database?\nWhy can\u2019t I just store UTC everywhere?\nHow often do things change in the world?\nWhy is this so hard?\n\nAll these are very normal questions to ask. And they cause problems when not handled properly in production.\nAnother very subtle but important nuance for this conference is that we live in a country (India) which only has 1 timezone and where daylight savings isn\u2019t observed. Hence, we have the privilege of having to never \u201cchange\u201d our watches and clocks unless we go our of our country somewhere. So unless we have some prior experience with dealing with date and time in software systems, most of us (me included) start in the dark.\nBuilding software however expects a clean understanding of dates and times and the associated nuances. \nOutline of the talk\nThis session aims to address 3 key points:\n\nIntroduce the audience to the concepts around time and date and timestamps\nHighlight the complexities that arise from storing timestamps\nGive practical advise on how to solve the complexities predictably in a production scenario\n\nThis talk aims to equip the audience with the concepts and knowledge they need to solve date and time problems in any environment / language they work in. There will also be code samples in Python to better illustrate the concepts.\nNot in scope\nThis talk will *NOT* deal with the problems of the scientific / high precision computing world where ideas like leap seconds are important.\n\n\n\nPrerequisites:\nThis talk is aimed at individuals who are beginners to the world of dates and times. The part about handling things in production will have information that will be of use to seniors to validate their approaches in systems they are responsible for as well.\n\n\n\nSpeaker Info:\nMy name is Shrayas and currently, I head the engineering efforts at a Logic Soft - a small organization with a large impact. Logic Soft is the only recognized software providers for the Book Trade businesses. If you have ever visited a popular book store anywhere in India, it is very likely that our software is running their business behind the scenes.\nAt Logic Soft I am responsible for all key technical and business decisions and have set a foundation for building the next generation of web and mobile applications in the organization. I enjoy building simple and future proof software with a focus on readability and scalability. I strongly believe that new technologies are not the right way to solve problems - simple & scalable design is.\nPreviously at SAP Labs, I worked on a small team that helped test and build out Sentinel - an Algorithmic Trading platform on a then new gen SAP database - SAP HANA\nOutside of work, I enjoys running very long distances, trekking mountains or whipping up something in the kitchen. I used to be the co-coordinator for Chennaipy and have spoken many times at monthly meetups. I was also one of the core organizers of PySangamam and PyCon India 2019.\nI write on shrayas.com occasionally.\n\n\n\nSpeaker Links:\n\nWebsite\nSlides from all the talks I have given at Chennaipy and other places\nContent from all the talks I have given. And other slides too\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b497b710-57d2-4734-9a71-4da9dbddb623": {"__data__": {"id_": "b497b710-57d2-4734-9a71-4da9dbddb623", "embedding": null, "metadata": {"Section": "Developer tools and automation", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "Kubernetes + Python: Unleashing the Power of Python Controllers", "speaker": "Yash Mehrotra (~yash2)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c2f845102c6e4e68fb0946c12afddd8bb8523af220d4b6657b498b19aa5adf5a", "text": "\n\nDescription:\nKubernetes has revolutionized container orchestration, enabling developers to build scalable and resilient applications. But, the true potential of Kubernetes can be unlocked by harnessing the power of custom controllers. In this talk, we will dive into the world of Python and Kubernetes, exploring how to build your own custom controllers to automate and manage your containerized environments.\nWith the groundwork laid, we'll explore practical examples of building Python-based controllers. By the end of this talk, you will have a solid understanding of how to build Python Kubernetes controllers, so that you can take control of your Kubernetes clusters, automate repetitive tasks, and customize your application deployment workflows.\nOutline\n\nPhilosophy of Kubernetes\nWhat are CRDs and how to extend kubernetes via them\nHow do controllers come into play\nDifferent parts of a controller\nLifecycle of different controller event streams\nBuilding our own controller to manage a stock portfolio\nBuilding a new controller which scales containers based on weather\n\n\n\n\nPrerequisites:\nIt would be helpful if attendees have a basic knowledge of containers and kubernetes (but not required)\n\n\n\nSpeaker Info:\nI've been working on and around developer tools for more than 5 years and have been involved in developer productivity initiatives in all the companies I've worked at. I've been both a Software Developer and a DevOps/Platform Engineer which helped me bridge the communication gap and bring my own unique experience to the problem.\nI currently work as a Senior Software Engineer at Flanksource where we are building a mission-control plane for enterprises.\nI've previously given talks at GopherCon, PyCon, RootConf and a few local meetups \n\n\n\nSpeaker Links:\nWebsite: https://yashmehrotra.com\nTwitter: https://twitter.com/yashm95\nGithub: https://github.com/yashmehrotra\nPrevious Talks: https://yashmehrotra.com/talks/\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "27365734-0c7a-42e7-9167-801e27d34e83": {"__data__": {"id_": "27365734-0c7a-42e7-9167-801e27d34e83", "embedding": null, "metadata": {"Section": "Others", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "Music Making with Python and FoxDot", "speaker": "Sangarshanan (~Sangarshanan)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "37f1321a810e4b68286ff1933e47d5bba4ca5dd1c9be822c61787d4d7dea6aba", "text": "\n\nDescription:\nA whimsical introduction to making music and live coding beats with Python, during this talk I will use FoxDot, Supercollider and write Python code while exploring different techniques for coding beats. We will code some music during the course of the talk and conclude with a fun live little musical live demonstration where i might even play an instrument along with the Python generated music provided the demo gods stand by my side!!\nHere is the proposed outline for the talk:\n\n(2 min) Introduction to live-coding\n\nwhoami\nwhat is live-coding\n\n(10 mins) Foxdot 101\n\nArchitecture - TkinterGUI + Supercollider\nInstallation and Setup\nMusical constructs in FoxDot\n\nBasic Player object states\nScheduling methods on objects\nTime variables i.e Clocks\nCoding repeatable Patterns\nCustom Samples and Synths\n\n\n(3 min) Beatmaking 101\n\nWhat goes into a beat\n\n(5 mins) Programming Constructs == Musical Contructs\n\nLive loops are just Loops !!\nIntervals are just Arrays !!\nSynths and Samples\nBasic beat + Synth Loop\n\n(5 mins) Conclusion\n\nDemo the Beat\nAdd some synth + Magical \u2728 instrument\nPossibilities !! Concurrency + Custom samples + Randomization and much more\n\n\n\n\n\nPrerequisites:\nPrior knowledge of basic Python and Programming constructs is expected which I bet everyone at a Python conference should have! This talk will be fairly easy to follow for anyone with little or no music or live-coding experience\n\n\n\nSpeaker Info:\nMy name is Sangarshanan and I am a Software Engineer from planet Earth. I love making stuff that helps and amuses me in equal measure and standing upside down while holding a banana. When I'm bored you can find me making absurdist memes, yet another spotify playlist or staring straight into the void\n\n\n\nSpeaker Links:\n\nGithub: https://github.com/sangarshanan\nYoutube: https://www.youtube.com/@sangarshanan\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "19a7161e-b375-45d6-bb3f-d31b8cbfbfa2": {"__data__": {"id_": "19a7161e-b375-45d6-bb3f-d31b8cbfbfa2", "embedding": null, "metadata": {"Section": "Culture and Society", "Type": "Talks", "Target Audience": "Beginner", "Last Updated": "14 Sep, 2023", "title": "Unleashing the Power of Python: Teaching Computer Science to Kids", "speaker": "Prasanna MG (~prasanna9)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e1baae958a5953772cf407394d3af53be492ec5aa26e114e024b11262574a35f", "text": "\n\nDescription:\nAbstract:\nIn the digital age, computer science is becoming an essential skill for young learners. As educators, it is our responsibility to make learning computer science fun, engaging, and accessible for children. This talk aims to showcase the immense potential of utilizing Python as a teaching tool to introduce computer science concepts to kids. By leveraging Python's simplicity, versatility, and real-world applicability, we can empower the next generation of problem solvers, critical thinkers, and creators.\nIntroduction:\nWelcome to our presentation on \"Unleashing the Power of Python: Teaching Computer Science to Kids.\" As technology continues to evolve, proficiency in computer science is increasingly vital for young minds. Python, known for its straightforward syntax and readability, has proven to be an excellent choice for introducing programming to children. Our proposal aims to explore the strengths of using Python as a teaching language for kids, highlighting how it can inspire creativity, curiosity, and a lifelong passion for computer science.\nObjectives:\n\nIntroduce Python as a powerful and accessible programming language for children.\nShowcase the benefits of using Python in fostering problem-solving skills and logical thinking.\nDemonstrate how Python enables creative and interactive learning experiences for kids.\nExplore real-world applications of Python to inspire young learners.\nShare success stories and case studies of Python-driven computer science education for kids.\n\nOutline: \n1. The Magic of Python:\n\nAn overview of Python's simplicity and readability. \nPython's position as a beginner-friendly language. \nComparing Python with other languages for kids' education.\n\n2. Fostering Problem-Solving Skills:\n\nHow Python's structure aids in understanding programming concepts.\nUsing Python to teach algorithms and data structures.\nPython's role in nurturing logical and computational thinking.\n\n3. Creativity Unleashed:\n\nIntroduction to game development using Python - pygame concepts.\nEncouraging kids to build their projects - robotics using raspberrypi, use of micro python.\n\n4. Real-world Applications:\n\nPython's relevance in various industries (e.g., web development, data analysis, automation).\nBuilding real-life projects to make computer science tangible and exciting, introduce ROS and python with the architecture.\n\n5. Success Stories:\n\nShowcasing examples of children excelling in computer science with Python.\nTestimonials from educators, parents, and students about Python's impact.\nHighlighting the long-term benefits of learning Python from an early age.\n\n6. Embracing the Future:\n\nCollaborating with schools, educators, and parents to promote Python-based computer science education.\nIntegrating Python into the curriculum and extracurricular activities.\nSupporting initiatives to make Python accessible to all children, regardless of background.\n\nConclusion:\nIn conclusion, Python offers a compelling gateway into the world of computer science for kids. By leveraging Python's strengths, we can cultivate a generation of young learners with the skills, confidence, and creativity to tackle the challenges of tomorrow. Together, let us embark on a journey to unlock the potential of Python and inspire the next generation of computer scientists.\n\n\n\nPrerequisites:\nNo pre-requisites\n\n\n\nContent URLs: \nYoungWonks\nMakerVidya\nInteresting Blogs\nYoutube Page\nInstructors\nProjects by our students\nYoungWonks - Computer Programming for Kids & Teens\n\n\n\nSpeaker Info:\nPrasanna is a drone enthusiast who loves building drones. He is an instructor at YoungWonks.\nHe has built autonomous drones capable of navigating around obstacles, integrated lidars and radars with drones. His drones can attain top speeds beyond 150kmph.\nHe has completed his Bachelors degree from Visvesvaraya Technological University, Karnataka, India.\nHe is proficient in Python and C++. He has also worked on neural networks and with computer vision. He loves tinkering with embedded computer boards such as the Raspberry Pi and the Jetson. He is very interested in automation and building projects related to robotics.\nIn his free time, he enjoys playing badminton and playing the guitar. He is an anime enthusiast and loves watching Naruto and One Piece.\n\n\n\nSpeaker Links:\nLinkedin pprofile\nInstructors at youngwonks\nGithub link\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "969cd152-ee2f-42d6-a69b-256b29c0291c": {"__data__": {"id_": "969cd152-ee2f-42d6-a69b-256b29c0291c", "embedding": null, "metadata": {"Section": "Core Python", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "13 Sep, 2023", "title": "Metaprogramming In Python", "speaker": "ABY M JOSEPH (~aby)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "932a2fbbdb960c2ffcfe66a7c6190f1266d8847424ce0edfae28be11d0b8c405", "text": "\n\nDescription:\n\"Metaclasses are deeper magic than 99% of users should ever worry about. If you wonder whether you need them, you don't (the people who actually need them know with certainty that they need them, and don't need an explanation about why).\" -Tim Peters\nMetaprogramming is writing programs that manipulate programs. Dive into the deeper python magic of metaprogramming and enhance your understanding of object orientation in Python and its working under the hood.\nMetaclasses are used in the internal implementation of Python enums and dataclasses and are used in designing various libraries including web servers (Django) and ORMs (Mongoengine). Get a head start into metaprogramming, deepen your understanding of pythonic object lifecycle and see the power of metaclasses in action.\n\n\n\nContent URLs: \nProposal Deck\n\n\n\nSpeaker Info:\nSpeaker 1: \nAby is a Product Engineer at UST working in the travel domain. With a keen eye for detail and a desire to improve, he is currently exploring more on the Python microservices and the GraphQL ecosystem.\nAby also has experience in resolving various business problems by combining purpose-led research and digital technology innovation with rapid prototyping.\nSpeaker 2:\nAswin is working as Product Engineer at UST, specialising in Python micro services and the GraphQL ecosystem. His hands-on experience in these domains enriches his perspective as a speaker, making him a valuable source of insights into technology, community building, and innovation. \nAswin is also a member of the Trivandrum Python community, dedicated to spreading his love for Python throughout his hometown. His mission is to create an inclusive space where Python enthusiasts of all levels can come together to explore the limitless possibilities of the language.\n\n\n\nSpeaker Links:\nSpeaker 1: Aby M Joseph \nLinkedin\nEuroPython '23\nSpeaker 2: M Aswin Kishore \nLinkedin\nGithub\nTwitter\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f62d01fa-6780-43ff-9550-9581f253b42d": {"__data__": {"id_": "f62d01fa-6780-43ff-9550-9581f253b42d", "embedding": null, "metadata": {"Section": "Scientific Computing", "Type": "Talks", "Target Audience": "Beginner", "Last Updated": "12 Sep, 2023", "title": "Unlocking the Cosmos: Querying Space Observatories with Python", "speaker": "Abhijeet Manhas (~abhijeetmanhas)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "f9b327ff5ed49464f0219a0b1369b944a01c608a4bc9aa62ea57396be2283fc3", "text": "\n\nDescription:\nAbstract\nPython is a powerful language for scientific computing, and it is especially well-suited for astronomy. In this talk, we will explore how Python can be used to query data from space observatories, satellites, and telescopes. We will start by discussing why Python is a good choice for this task, and then we will look at some of the most popular libraries for querying astronomical data. We will also discuss some case studies that demonstrate how Python can be used to analyze data from space.\nThe information streaming in from these instruments contains invaluable insights into celestial phenomena, including galaxies, stars, exoplanets, and cosmic events. Astronomy has been revolutionized by the deluge of data generated by these celestial instruments. This talk aims to equip participants with the skills needed to harness this data for scientific computing.\nTalk Outline\nIntroduction to Python for astronomy\n\nWhy Python is a good choice for astronomy\npopular Python libraries for astronomy\nQuerying astronomical data with Python\nHow to access astronomical data from public archives\nHow to use Python libraries to read and manipulate astronomical data\nScientific computing with Python\nHow to use Python to perform mathematical operations on astronomical data\nHow to use Python to visualize astronomical data\nCase studies\nHow to use Python to analyze solar data\nHow to use Python to search for exoplanets\nConclusion\nWhere to learn more about Python for astronomy\nContributing to pyAstro ecosystem\n\n\n\n\nPrerequisites:\n\nThis talk is intended for Python programmers who are interested in learning more about how Python can be used for astronomy. No prior experience with astronomy is required.\n\n\nbasic python proficiency\nelementary knowledge about astronomy\ncuriosity :)\n\n\n\n\nContent URLs: \nContent\n\ndraft slides for talk\nblog for sunpy contributions\n\nCode\n\ncollab notebooks with code\nSunPy Github repository\nipynb notebook for fetching galaxy images\n\n\n\n\nSpeaker Info:\nAbhijeet Manhas is Software Engineer at Amazon. Graduated from IIT Mandi with bachelors in Computer Science, he is Interested in AI, Cross-platform development, and Scientific computing with passion of building solutions for real-life problems. \nAs Google Summer of Code student in OpenAstronomy organization; he contributed to solar physics python library SunPy to enhance it capabilities to query data from solar observatories. He was project lead for an initiative by International Astronomical Union OAD to uplift Astronomy in Himalayas.\n\n\n\nSpeaker Links:\nAbhijeet Manhas\n\nLinkedIn: https://www.linkedin.com/in/abhimanhas/\nGithub: https://github.com/abhijeetmanhas\nMedium blogs: https://abhimanhas.medium.com/\nOpen source contributions: https://github.com/abhijeetmanhas/abhijeetmanhas/blob/master/GSoC2020-Fido-WorkProduct.md\nTwitter: https://twitter.com/astromanhas\nWebsite: https://abhijeetmanhas.github.io\n(Volunteering) International Astronomical Union project page: https://www.astro4dev.org/upliftment-of-space-technology-and-astronomy-cell-in-himalayas-india/\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2a8669b6-6c87-4bb9-a690-1f2413c4221b": {"__data__": {"id_": "2a8669b6-6c87-4bb9-a690-1f2413c4221b", "embedding": null, "metadata": {"Section": "Data Science, AI & ML", "Type": "Talks", "Target Audience": "Advanced", "Last Updated": "14 Sep, 2023", "title": "PyVelox: Interfacing Python bindings for the unified execution engine by Meta", "speaker": "Sanjiban Sengupta (~sanjiban)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "6019dc8ab86e99e5ff77cad2789348ff373f5d3fe5c182a29377bfa846a9d096", "text": "\n\nDescription:\nVelox, an open-source project by Meta, is a C++ database acceleration library which provides high-performance components for processing huge datasets. Voltron Data, in collaboration with the Meta open-source team, has been developing PyVelox, a Python package that adds bindings to commonly used Velox APIs. This addition empowers Velox developers to leverage Python\u2019s interactive REPL, enabling them to efficiently explore and triage Velox vectors and associated data components. Consequently, PyVelox enables Python developers to execute data queries, including SQL queries, across a wide spectrum of workloads such as batch processing, stream processing, AI/ML, and more.  \nVelox stands out as a unified engine for data execution, offering a versatile execution engine that seamlessly integrates with diverse data compute architectures. This integration minimizes redundancy while extending consistent functionality across various frameworks. Currently, Velox finds applications in engines like Presto and Apache Spark, alongside Meta's internal streaming service XStream, with integration plans underway for Apache Flink. Previously, say for a data compute architecture built on Spark or Presto, the user needed the respective engine for the execution of data queries, however, Velox facilitates using the same execution engine for both of them, thus unifying the process for any data compute operation. This unification not only reduces complexity but also ensures universal semantics throughout the entire data lifecycle, thus features generated during ad hoc training, or online execution remain consistent.  \nIn this talk, we aim to briefly discuss Velox, its philosophy and methodology. Following this, we shall move to PyVelox, its data types, expressions, and functionalities, thus demonstrating the simplicity of running database queries on Velox using Python APIs without losing efficiency.\n\nOutline: \n\nVelox Incubation\n\nOpen-sourced by Facebook in late 2021.\n\nVelox development over the years\nNeed for PyVelox\nPyVelox Developments\n\nData types\nExpressions\nSerialization-deserialization\nConversion to-and-from Apache Arrow\nType and function signatures\n\nDemo\nPyVelox future goals\n\n\n\n\nPrerequisites:\nKnowledge of data engineering and analytics will be helpful. The project is an execution engine, that can be integrated into a data compute architecture, so experience with SQL or data relational queries will be beneficial. The talk will include topics on Python bindings based on pybind11, thus Python and intermediate C++ knowledge is expected.\n\n\n\nContent URLs: \nDraft Presentation \nProject GitHub Link \nProject Webpage \nProject Documentation \n\n\n\nSpeaker Info:\nSanjiban works as a Software Engineer with the Data Engineering team at Voltron Data. His work primarily focuses on the development of open-source projects such as Apache Arrow, Substrait, and Velox by Meta. He co-created Substrait Fiddle, which is an online tool to prototype, visualize and share data relational queries based on the substrait specification. As a part of Voltron Data, he collaborated with the Meta open-source team for developing PyVelox, particularly implementing the support for Arrow-Velox conversion, complex data types, etc.   \nSanjiban has been working in the open-source data science and engineering domain since his junior year of college in 2021. He was accepted to participate in Google Summer of Code 2021 for CERN-HSF and thus worked on developing storage functionalities for deep learning models. A year later, he was selected to participate in the CERN Summer Student Program in Geneva, Switzerland, and worked on enhancing TMVA SOFIE: which is a fast machine learning inference engine by CERN. In SOFIE, he was particularly involved in the development of the Keras and PyTorch Parser, machine learning operators based on ONNX standards, Graph Neural Networks support, etc. Moreover, he volunteered as a Mentor for the contributors of Google Summer of Code 2022, and again in 2023, and the CERN Summer Students of 2023 working on CERN\u2019s ROOT Data Analysis Project.\nSanjiban finds hackathon and ideation events very interesting, and has participated in many of them in different levels. Previously, he has worked with various startups as well as corporations, thus gaining industrial experience. During college, he acted as the Vice Chair, and then the Chair of the ACM Student Chapter of IIIT Bhubaneswar. He also acted as the ML Head of various student technical societies.\nHis work on CERN's TMVA SOFIE Machine Learning Inference Engine has been published/presented as follows:\n\nMoneta L., Sengupta S., Hamdan A. \"New developments of TMVA/SOFIE: Code Generation and Fast\nInference for Graph Neural Networks\". Oral Presentation at 26th International Conference on Computing in\nHigh Energy & Nuclear Physics; May 2023; Virginia, USA \nSitong An, Sanjiban Sengupta et al. C++ Code Generation for Fast Inference of Deep Learning Models\nin ROOT/TMVA. 2023 Journal of Physics: Conference Series 2438 012013 \nAn S., Moneta L., Sengupta S., Hamdan A. Shah N., Shende H., Mittal S., Zapata O. \"ROOT Machine\nLearning Ecosystem for Data Analysis\". Poster presented at 21st International Workshop on Advanced\nComputing and Analysis Techniques in Physics Research; October 2022; Bari, Italy. \nAn S., Moneta L., Sengupta S., Hamdan A., Sossai F., Saxena A. \"SOFIE: C++ Code Generation from\nROOT/TMVA for Fast Deep Learning Inference\". Poster presented at 20th International Workshop on\nAdvanced Computing and Analysis Techniques in Physics Research; November 2021; Daejeon, South Korea. \nSengupta S. \"TMVA SOFIE: Enhancing the Machine Learning Inference Engine\". A report published for\nthe CERN Summer Student Program; December 2022; Geneva, Switzerland.\n\n\n\n\nSpeaker Links:\nPast talks:  \n\nTMVA SOFIE: Developing the Machine Learning Inference Engine \nCERN Student Sessions 2022, Geneva; August 2022 \nLink to talk \nROOT Storage of Deep Learning models in TMVA \nCERN-HSF\u2019s GSoC 2021 End of Program Presentation Series; August 2021 \nLink to talk \n\nGitHub Profile \nLinkedIn Profile \nSpeaker's Personal website\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f9a3090e-aa3f-4e2f-a10b-2c30db78083a": {"__data__": {"id_": "f9a3090e-aa3f-4e2f-a10b-2c30db78083a", "embedding": null, "metadata": {"Section": "Data Science, AI & ML", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "18 Sep, 2023", "title": "Evaluating Generative Vision Models: Insights into the Fr\u00e9chet Inception Distance and CLIP", "speaker": "Mayank Khanduja (~mayank0)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "2771069395a87149867d723abc7698ddf38b875d0f5ec2246d58ab540822eb35", "text": "\n\nDescription:\nThere are plenty of Generative AI models for Computer Vision in the industry and numerous techniques to evaluate those models. However, none of the evaluation techniques can surpass the human level of evaluation for these models. Unlike object detection, segmentation and classification models, which machines can evaluate better than humans, generative models like Stable Diffusion, StyleGAN, CycleGAN, and Pix2Pix require both quantitative and manual inspection to evaluate their performance. \nIf a user sees hundreds of generative pretrained vision models on online platforms like HuggingFace or Kaggle, how will they evaluate and select the best model suitable for their dataset? Additionally, if they train their own model, how will they know how robust the trained model is? \n Manually inspecting thousands of generated images by the model is quite challenging and time-consuming; hence, an evaluation metric is required to measure it quantitatively. This is a highly active area of research currently.  \nWe will cover two metrics\n\nFr\u00e9chet Inception Distance (FID) which compares two sets of images by leveraging a pre-trained InceptionNet model.\nCLIP Score which measures compatibility of Image-Caption pairs by leveraging a pre-trained CLIP model. \n\nThese metrics are industry standard for their respective tasks currently.\nOutline of the Talk\n\nChallenges faced while evaluating Generative vision models.\nProperties of AI generated images/text that need to be considered for evaluation\nGain an intuitive understanding of FID and CLIP score.\nUnderstand the metrics mathematically and derive the formula.\nImplementation of the derived formula in python.\nApply the python code on a use case by comparing two generative models on a particular dataset.\nLook into a few caveats of these metrics on some uncommon datasets and explore how we can tackle them.\n\nIn the code, we will use PyTorch and some basic Python libraries for our task.\nKey takeaways from the talk\n\nYou will get to know how close these metrics perform as compared to human judgement.\nResearchers will be able to compare their models with the existing benchmarks.\nDevelopers will get to know when to replace their models based on these metrics without human intervention.\nYou will deeply understand the equations behind these metrics and implement them in python from scratch.\n\n\n\n\nPrerequisites:\nBasic knowledge of Python, Convolutional Neural Networks and Statistics\n\n\n\nSpeaker Info:\nMayank Khanduja is a Data Scientist at Esri R&D center with five years of experience in the industry. He has worked on the development of Generative Adversarial Networks in his current organization and has also published informative guides and blogs.\n\n\n\nSpeaker Links:\nhttps://www.linkedin.com/in/mayank-khanduja-554607130/ \n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "59cd531b-c008-478e-ac5f-7742b8a8939e": {"__data__": {"id_": "59cd531b-c008-478e-ac5f-7742b8a8939e", "embedding": null, "metadata": {"Section": "Game Design and 3D Modelling", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "Programming Minecraft with Python", "speaker": "Anand S (~anand)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "427e0b27f30c2081e94a42f5b22411b49404b0720d06d575f5f21bd0426d658f", "text": "\n\nDescription:\nMinecraft is the best-selling video game of all time, with 200 million copies sold. It's a full-fledged 3D construction environment.\nIt looks chunky at first, but you can create beautiful worlds. It turns out that Minecraft is quite programmable. You can send messages using WebSockets that can place blocks, create mobs, get information, and more.\nUnfortunately, this is not officially documented. This talk is a guide to the reverse-engineered Minecraft WebSocket protocol, and how to control make Minecraft do anything using Python.\n\n\n\nPrerequisites:\nA working knowledge of Python\n\n\n\nContent URLs: \n\nCode: https://github.com/sanand0/minecraft-websocket/tree/master/tutorial\nVideo: https://www.youtube.com/watch?v=o-NgvtJZDcY\n\n\n\n\nSpeaker Info:\nAnand is a co-founder of Gramener, a data science company. He leads a team that automates insights from data and narrates these as visual data stories. He is recognized as one of India's top 10 data scientists and is a regular TEDx speaker.\nAnand is a gold medalist at IIM Bangalore and an alumnus of IIT Madras, London Business School, IBM, Infosys, Lehman Brothers, and BCG.\nMore importantly, he has hand-transcribed every Calvin & Hobbes strip ever and dreams of watching every film on the IMDb Top 250 (except The Shining).\nHe blogs at https://s-anand.net. His talks are at https://bit.ly/anandtalks\n\n\n\nSpeaker Links:\n\nTalks: https://s-anand.net/blog/talks/\nGithub: https://github.com/sanand0\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5887efcc-a9c5-46c8-9c64-6f74a9eb36d2": {"__data__": {"id_": "5887efcc-a9c5-46c8-9c64-6f74a9eb36d2", "embedding": null, "metadata": {"Section": "Developer tools and automation", "Type": "Talks", "Target Audience": "Beginner", "Last Updated": "12 Sep, 2023", "title": "Embracing Observability in Modern Python Applications: Harnessing the Power of OpenTelemetry", "speaker": "Angelin John (~angelin)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "79cf299b6e57e2fe64e799348d21602d8bb17d4aa119f331cee552b81c48111d", "text": "\n\nDescription:\nAs technology continues to advance, software development has also evolved significantly. The days of using monolithic applications are over, and we now embrace cloud-based architectures, distributed systems, and microservices to improve scalability and agility. However, these advancements have brought new challenges in monitoring and debugging software. In this informative talk, we will explore the concept of Observability and how it is transforming the landscape of monitoring and debugging modern Python applications. We will also delve into the crucial role played by Opentelemetry, a revolutionary project that allows developers to gather telemetry data with ease and trace the journey of each request through distributed systems. The audience will gain valuable insights into different ways to view their telemetry data and troubleshoot issues that may arise. \nOutline of the talk\n\nThe limitations of traditional monitoring\nIntroduction to Observability\nHarnessing the power of OpenTelemetry\nSimplifying tracing from boilerplate to elegance\nPotential and concerns of building an observable system\n\n\n\n\nPrerequisites:\nNone, but people with atleast a year of experience could relate better\n\n\n\nVideo URL:\nhttps://www.youtube.com/shorts/hckRWuhQvIY\n\n\n\nContent URLs: \nThe majority of the content will be based out of the blog given below with a basic outliner on opentelemetry.\nhttps://angelinjohn.com/index.php/2023/08/05/embracing-observability-in-modern-python-applications-harnessing-the-power-of-opentelemetry/\n\n\n\nSpeaker Info:\nI am Angelin John, a seasoned full-stack software engineer with an exciting journey spanning six years, during which I have honed my expertise in React, Java, Python, and Django. As an Associate Technical Lead at KeyValue Software Systems, I am passionate about collaborating with diverse teams to create innovative and cutting-edge products that make a real impact.\nBeyond my technical role, I take great pride in being a Google Women Techmakers Ambassador, advocating for diversity and inclusion in the tech industry. Empowering and supporting women in technology is a cause close to my heart, and I am dedicated to fostering an inclusive and supportive tech community.\nThroughout my career, I have shared my knowledge and experience through workshops and information sharing sessions, both within my workplace and at various colleges. Mentoring aspiring developers and guiding them on their journey brings me immense joy and satisfaction.\nBeing deeply connected to the local startup and developer communities in Kerala, I believe in the power of collaboration and community-driven innovation. Working alongside these passionate individuals has been a source of constant inspiration.\n\n\n\nSpeaker Links:\nMedium \nLinkedin\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5080e8e8-1210-4954-9df4-9ae9f54a378c": {"__data__": {"id_": "5080e8e8-1210-4954-9df4-9ae9f54a378c", "embedding": null, "metadata": {"Section": "Data Science, AI & ML", "Type": "Talks", "Target Audience": "Beginner", "Last Updated": "12 Sep, 2023", "title": "AI Engineering in Python: System Design 101", "speaker": "Nirant Kasliwal (~NirantK)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "be4ef0d20c3bb2bb67f49c5eea57e6d42ed12ab3eab48f0e98cab9419dff481a", "text": "\n\nDescription:\nLLM-based applications are a critical component of modern AI workflows. This is a system design primer for ML beginners wanting to focus more on the concepts than specific tools and models. At the same time, I recommend Python-first tools Open Source tools to help beginners good and recent choices.\nWe use two main driving examples to help folks reason through the problems: Retrieval Augmented Generation \u2014 this is the method used for every \"Chat with your Data\" solution:\nChat with your Data\n\nRAG System Outline \u2014 Best Practices\nImproving Ranking\nScaling it Up\nImproving Reliability\n\nThis talk is accessible, welcoming and at the same time enriching to anyone who'd find an opinionated introduction to AI Engineering useful!\n\n\n\nPrerequisites:\n\nAbility to work with REST requests in Python e.g. some FastAPI/Flask/Django is more than enough\nPlayed with or used ChatGPT-like Interfaces\n\n\n\n\nContent URLs: \nPyCon India 2023 Slides are here\nI'd given a version of this talk recently at IIT Madras' AI4Bharat as well, which was more suitable for academia than PyCon. The talk was very well received with multiple Professors from across multiple departments sitting through the entire session and asking good questions.\n\n\n\nSpeaker Info:\nMe in 3 bullet points:\n\nACL 2020 NLP Paper on Hinglish, first Hindi-LM: Hindi2Vec\nNLP Book with 5000+ copies sold\nFor Stanford CS230 Deep Learning, Dr. Andrew Ng recommends my work [Awesome NLP](\n\nSpoke at PyCon2019 in Chennai: https://youtu.be/UM56FDjSx9g\nAs a Machine Learning Engineer, I have:\n\nDeployed Sentence Transformers and Annoy (vector search library) for cosine Similarity powered search in 2018 in production\nManaged a team of 3 engineers to build a support chatbot for 1M chat messages per month\nCreated Hinglish LM Dataset and Model for Hindi-English Code-Switching\n\nAs an AI Engineer, I have\n\nBuilt and deployed Question Answering systems for 3+ years, including production-grade projects with OpenAI LLMs e.g. text-davinci-003, GPT3.5 and GPT4\nBuilt guardrails, evals to reduce hallucinations and deployed summarization and question answering systems\n\n\n\n\nSpeaker Links:\n\nBlog \nAbout Me\nGithub: Selected Repositories: AwesomeNLP, AgentAI, FastEmbed, Companion Code for my Book: NLP in Python\nTwitter\nLinkedin\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2aeaa010-0714-4276-809f-29a6cfa1a133": {"__data__": {"id_": "2aeaa010-0714-4276-809f-29a6cfa1a133", "embedding": null, "metadata": {"Section": "Developer tools and automation", "Type": "Talks", "Target Audience": "Beginner", "Last Updated": "12 Sep, 2023", "title": "Talking to the Linux Kernel with Python and eBPF", "speaker": "Navin Pai (~navin57)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e5ccefa23a4cd175d3d09d60f6d9f921aa954090f5d52737b517471486ebd8ef", "text": "\n\nDescription:\nThe Linux kernel is a complex piece of software, but it can be difficult to interact with from userspace. Extended Berkeley Packet Filters (eBPF) is a new technology that allows you to write programs that run in the kernel, but interact easily with a program in userspace. And as with most modern usecases, Python provides a powerful and easy-to-use interface for writing eBPF programs.\nIn this talk, we'll show you how to use Python and eBPF to talk to the Linux kernel. We'll start by covering the basics of eBPF, including how it works and how to write eBPF programs. Then, we'll show you how to use Python to interact with eBPF programs. We'll also provide examples of some real-world use cases for Python-powered eBPF, such as:\n- Tracing kernel functions\n- Implementing custom network filters\n- Monitoring memory allocation calls made by userspace applications\n\nWe'll also touch on some of the OSS tools that leverage eBPF in different and varied ways and understand the building blocks that they use (eg. Pyroscope, Cilium, Katran, Calico). By the end of this talk, the expectation is that you'll be able to build your own custom eBPF programs, what are the interesting things you can do with eBPF, and have a deeper understanding on how to \"communicate\" with your kernel using Python.\n\n\n\nPrerequisites:\nNone. This talk is intended to be a beginner talk to highlight what eBPF is, and how easy it is to write python programs that can leverage eBPF for a host of different use-cases\n\n\n\nSpeaker Info:\nNavin is a Founding Engineer at OpsVerse Inc., where he's part of the core team that's building managed, modern, OSS-based tool ecosystems for DevOps. Prior to OpsVerse, he was a Principal Engineer at Tact.ai. He's been a Pythonista for over a decade, and has been responsible for architecting out multiple large systems that have grown to become internet-scale over the years. He is also a vocal proponent for the use of OSS within the broader business ecosystem, both in India and beyond.\nWhile he's not talking tech, you can find him ranting about soccer, economics, and pop culture. In his free time, he enjoys writing about himself in the third person in \"Speaker Information\" sections of CFPs :)\n\n\n\nSpeaker Links:\nSocial\nhttps://github.com/navinpai/\nhttps://lifeofnav.in/\nhttps://twitter.com/navinpai\nSome Previous Talks\nAnthill Inside: https://www.youtube.com/watch?v=_WOpi0KvHk8\nPyCon India: https://www.youtube.com/watch?v=DeCozoEgUQU\nOpsVerse Webinar: https://www.youtube.com/watch?v=sJnQwla_nZE\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3394821a-62b9-40e9-846d-39ca712fb7b2": {"__data__": {"id_": "3394821a-62b9-40e9-846d-39ca712fb7b2", "embedding": null, "metadata": {"Section": "Cloud Computing", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "Unlock the Power of Automation: Codify AWS Infrastructure with Python CDK", "speaker": "Dheeraj Choudhary (~dheeraj3choudhary)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "d8720e2b402cf13d6462553c34df3be8e6a7ce7a1f2049e0dc8697b6e00ea75c", "text": "\n\nDescription:\n\nExplore how Python CDK empowers developers to leverage the power of code to automate the provisioning and management of AWS resources. \nLearn how Python CDK simplifies the process of defining and deploying infrastructure using familiar programming languages, enhancing flexibility and productivity. \nDiscover how Python CDK enables you to codify your AWS infrastructure, bringing scalability, maintainability, and reusability to your infrastructure deployments.\n\n\n\n\nPrerequisites:\nCore Python Knowledge\n\n\n\nContent URLs: \nhttps://docs.aws.amazon.com/cdk/api/v2/python/index.html\n\n\n\nSpeaker Info:\nLead Engineer At EPAM System with 10+ years of experience as a DevOps / Build and Release Engineering, Software configuration management in automating, build, deploy and release, cloud providers and APIs for Amazon (AWS) and likes to Share Knowledge contributing to Open Source community which mainly includes Cloud, DevOps,Linux etc. Currently accredit as an AWS Community Builder ,AWS User Group Pune Organizer, Hashicorp Ambassador, Hashicorp User Group Pune organizer.\n\n\n\nSpeaker Links:\n\u270f\ufe0f BLOG WEBSITE- https://dheeraj3choudhary.com/\n\ud83d\udcbc LINKEDIN - https://www.linkedin.com/in/dheeraj-choudhary/\n\u2764\ufe0f YouTube - https://www.youtube.com/@dheeraj-choudhary/\n\ud83c\udf10 INSTAGRAM - https://www.instagram.com/dheerajtechinsight/\n\ud83d\udd25 GITHUB - https://github.com/dheeraj3choudhary\n\ud83c\udf10 TWITTER - https://twitter.com/DheerajC30\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "cea42dcc-7939-4ccd-b9b2-de1603402993": {"__data__": {"id_": "cea42dcc-7939-4ccd-b9b2-de1603402993", "embedding": null, "metadata": {"Section": "Core Python", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "Evolution of Type hints in Python", "speaker": "Sasidhar Donaparthi (~sasidhar)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "5b3408a5b261a5956ec2abd91441aa85c25c027c3ab7a6be9d3ab3433b4a693c", "text": "\n\nDescription:\nThis talk is focused on how Type hints have evolved over multiple versions of Python ( 3.0 to 3.11). Provide examples of how type hints can be used in Python 3.11 for more readable code. I will cover various PEPS involved in improving the type hints. I will also cover Type Aliases, New Type, User defined Generic Types\n\n\n\nPrerequisites:\nBasic knowledge of Type hints\n\n\n\nContent URLs: \nIn progress - will be provided much before the event\n\n\n\nSpeaker Info:\nI am a mechanical engineering graduate with 25+ years of experience in manufacturing and financial services domains, I have started my career as design engineer in hydraulic turbine manufacturing company. After spending 5 years, I have stated my IT journey at Aspect Development/i2 Technology. I have worked primarily on data scrubbing, modelling, analysis and data migration projects for supply chain management. I then joined technology services side of Fidelity, financial services company. I have been using python for last 6+ years for automation, data analysis, web development, etc. I am very excited about the endless opportunities that arise in day today work and application of python for solving problems, automating day to day activities. I am very passionate about teaching python to engineering students thru pythonexpress program. I conduct regular training sessions for data analys ( numpy, pandas and matplotlib) in my company.\nI am a regular speaker at Pycon India conference. I have done various talks and workshops in Pycon 2017, 2018, 2022.\n\n\n\nSpeaker Links:\ngithub link - https://github.com/sdonapar\nlinkedin profile - https://www.linkedin.com/in/sasidonaparthi\ntwitter handle - @sdonapar\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9f7656c2-1a46-4e32-94ae-c66f9636aee4": {"__data__": {"id_": "9f7656c2-1a46-4e32-94ae-c66f9636aee4", "embedding": null, "metadata": {"Section": "Data Science, AI & ML", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "Revealing Uncommon Tricks: 25 Obscure Pandas & NumPy Hacks learnt over 5 years of being a Data Scientist", "speaker": "Nitin Kishore Sai Samala (~snknitin)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "8013eb718f95c2baaa9ed0e45c39720752a82a77d389675fb6208ccfdb4e7c5c", "text": "\n\nDescription:\nPandas and NumPy are indispensable tools in the arsenal of any data scientist, providing a solid foundation for data manipulation, analysis, and scientific computing. Over the course of five years in the data science realm, I have delved deep into these libraries, unearthing lesser-known, yet incredibly powerful hacks that have transformed my data workflows. In this enlightening talk, I will share 25 obscure Pandas & NumPy hacks that will revolutionize the way you approach data challenges and elevate your data science prowess to new heights.\nThe talk will commence with an introduction to Pandas & NumPy, covering their key functionalities and popular use cases. Building upon this foundation, we will embark on a captivating exploration of lesser-known hacks that can save you valuable time and streamline your data science pipelines. Ideally, they should become an indispensable part of your future workflows.\n\nEfficient Groupby Aggregations:\nHarness the hidden power of custom aggregation functions and optimized groupby operations to compute complex aggregations swiftly, achieving remarkable performance gains.\nTransforming Data with Custom Functions:\nUnravel the art of using NumPy's vectorized functions and Pandas' apply method to efficiently transform data based on your unique requirements.\nMerging DataFrames with Fuzzy Matching:\nExplore the world of fuzzy matching using Pandas' merge_asof and merge_ordered functions, allowing you to join data with less strict matching criteria.\nPivot Tables with Multi-Index and Multi-Level Columns:\nElevate your data summarization game by creating advanced pivot tables with multiple levels of indexing and columns, unleashing powerful insights.\nFastest Way to Drop Duplicates:\nDiscover a lesser-known approach to drop duplicates with lightning speed and a better selection criteria across columns, perfect for handling large datasets efficiently.\nPandas DataFrame Styling and describe settings:\nDive into Pandas' styling capabilities, enabling you to present your data with striking visualizations and aesthetic improvements.\nNumPy Broadcasting Tricks:\nUnveil NumPy's broadcasting capabilities and clever tricks that enable you to perform operations on arrays of different shapes seamlessly.\nHandling Missing Data with NumPy:\nMaster the art of dealing with missing data effectively using NumPy's masked arrays and advanced indexing techniques.\nFiltering Rows with NumPy's np.where:\nLearn how to leverage np.where to conditionally filter rows in NumPy arrays, enabling you to simplify complex logic.\nSmart Memory Management with Chunked Processing:\nHarness the power of chunked processing to optimize memory usage when working with large datasets, without sacrificing performance.\nCreating Interactive Visualizations with Seaborn and Plotly:\nCombine the power of Seaborn and Plotly to create interactive visualizations that tell compelling data stories.\nPowerful Time Series Analysis with Pandas:\nUncover lesser-known Pandas time series functionalities, such as rolling windows, resampling, and time zone conversions, to perform advanced stats analyses.\nElegant Handling of Categorical Data:\nDiscover Pandas' categorical data type and its potential to optimize memory usage and enhance performance for categorical variables.\nThe Right way  to fillna:\nDeal with your pesky Nans and <NA> types before they come back to bite you during training.\nNumPy's Fast Fourier Transform (FFT):\nUnlock the potential of NumPy's FFT for extracting frequency-domain features from time series data, enabling advanced signal processing.\nSpeed Up Data Reading with Dask and Vaex:\nDive into the world of powerful parallel computing libraries, to efficiently read and process large datasets in parallel.\nMemory Mapping with NumPy:\nUncover the lesser-known memory mapping functionality of NumPy to efficiently read and write large arrays from disk.\nSimplify Missing Data Imputation with NumPy Masked Arrays:\nLearn how to handle missing data using NumPy masked arrays, offering a clean and intuitive approach to imputation.\nEffortless Broadcasting in Pandas:\nMaster the broadcasting capabilities of Pandas to perform element-wise operations on DataFrames with different shapes.\nInplace application with Pandas' agg:\nExploit the versatility of Pandas' agg function to compute multiple aggregations efficiently in a single step.\nSavepoint: Ditch the CSV:\nDifferent ways of saving and loading dataframes into Pandas\nHandling Complex Data Structures with Pandas and NumPy:\nCombine the strengths of Pandas and NumPy to handle complex data structures and multi-dimensional arrays with ease.\nOptimize Categorical Data Conversion with pd.factorize:\nDiscover pd.factorize, an efficient method for converting categorical data to numerical representation.\nUnpacking Timestamps in Pandas using fast.ai helper:\nExplore Pandas' feature engineering capabilities, to do efficient time-based analysis to the second.\nAutomate Your EDA with pandas-profiling:\nExplore advanced Pandas and NumPy techniques for efficiently processing and analyzing massive datasets with ease.\n\n*Some of these may be subject to change with respect to the duration of the talk and ease of clustering *\nKey Takeaways:\n\nAcquire 25 lesser-known Pandas & NumPy hacks to optimize data manipulation and analysis workflows.\nEnhance data cleaning, transformation, and summarization techniques with powerful and efficient methods.\nElevate your data visualization capabilities using Pandas and Plotly for interactive and appealing visualizations.\nBoost your efficiency in handling big data with smart memory management and chunked processing techniques.\n\nOutline:\n\nIntroduction to Pandas & NumPy (5 minutes)\n\nOverview of key functionalities and applications\nPopular use cases in data science\n\n25 Obscure Pandas & NumPy Hacks (20 minutes)\n\nEach hack will be presented with a code snippet and practical use case\nHacks will cover data manipulation, optimization, visualization, and more\n\nKey Takeaways and Closing Remarks (5 minutes)\n\nRecap of the 25 hacks and their potential impact on data science workflows\nEncouragement to apply these hacks creatively in real-world projects\n\n\nJoin me on this data science talk as we unveil 25 lesser known hacks using Pandas & NumPy, and empower you with the tools to become a more efficient, effective, and resourceful data scientist. Whether you're a seasoned practitioner or a budding data enthusiast, these hacks will undoubtedly take your data science skills to the next level. Let's learn together, to perform better data manipulation techniques!\n\n\n\nPrerequisites:\nBasic understanding of Python, Data manipulation for ML/DL models, Experience using packages like Pandas and Numpy for working on some data science projects.\n\n\n\nSpeaker Info:\nA Jack-of-all-trades with a Masters in Computer Science and a Minor in Data Science. I graduated from UMASS Amherst in 2018 and am a Staff Data Scientist. My undergrad was done from BITS Pilani. I love solving puzzles/ciphers, deductive reasoning and tackling real-world challenges that require learning and combining different concepts.\nMy name is a palindrome, and I\u2019m a polymath and a polyglot (First Language is Python\ud83d\udc09 ). I aim to be an expert generalist across all the subfields and domains of AI, and I am perpetually working towards it. Life is a constant struggle between being a member of the community and standing out as an individual. I find a balance between both. I\u2019m not big on introductions because actions speak louder, and I believe people should grind until they no longer have to introduce themselves.\n\n\n\nSpeaker Links:\nI have delivered 2 talks prior to this - \n1) RE-WORK Applied AI Summit, San Francisco, Jan 2020. \n2) Walmart AI Summit, Bangalore, April 2022. \nYou can find the links to these here- https://snknitin.github.io/talks/\nSome additional redirects for the intrigued : \n\ud83c\udf10 Website \n\ud83d\udcdc Blogs \n\ud83e\udd16 Open Source Contribution \n\ud83d\udc31\u200d\ud83d\udcbb Github \n\u26d3\ufe0f LinkedIn. \n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "46c3a357-f67e-4589-9a63-0221fd700bfc": {"__data__": {"id_": "46c3a357-f67e-4589-9a63-0221fd700bfc", "embedding": null, "metadata": {"Section": "Web & App development", "Type": "Talks", "Target Audience": "Beginner", "Last Updated": "12 Sep, 2023", "title": "Architecting Scalable Python micro-services with GraphQL: Valuable Lessons and Best Practices", "speaker": "abhinand-c"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "45dbb469a714005f070cc5fbf3c9a2d1ac3c72432b9eeda189794769e3dffe91", "text": "\n\nDescription:\nIn this engaging and informative talk, we will explore the art of architecting scalable Python microservices using GraphQL as the foundation. The speaker will demonstrate the step-by-step process of building a GraphQL-based Python microservice utilizing the powerful combination of Graphene, FastAPI, and MongoDB. Throughout the session, the audience will gain valuable insights into best practices and discover the challenges encountered during the development process at the speaker's company. Whether you are a GraphQL enthusiast, a Python developer, or simply interested in microservices architecture, this talk promises to equip you with practical knowledge and real-world experiences to create high-performance, scalable microservices with confidence.\nThis talk will cover:\n\nIntroduction & Exploring the Technology Stack\nGraphQL Schema, Queries & Mutations\nBuilding the GraphQL Python Microservice & Schema Federation\nChallenges Faced and Lessons Learned\nBest Practices for Scalability (Schema Design, Caching & Concurrency)\nMonitoring and Debugging\n\nThe talk will provide a comprehensive journey through the process of architecting scalable Python microservices with GraphQL while showcasing real-world scenarios encountered. Attendees will leave with practical knowledge, best practices, and newfound confidence to build their own high-performance, scalable microservices in Python.\n\n\n\nSpeaker Info:\nI'm a software developer who loves to experiment with tech, spend time learning new technologies and build products fueling my desire to innovate for a better future.\nI currently work as a Product Engineer at Strollby Team in UST, developing and scaling Python based GraphQL micro-service. Apart from work, I'm engaged in a voluntary project with Kerala Police Cyberdome, pursue hobby projects and contribute in open-source community.\nI had opportunities to work alongside great teams in start-up eco-system, participate in various hackathons, take workshops to exciting peers and even give tech talks at conferences like PyConf HYD and EuroPython Conference.\n\n\n\nSpeaker Links:\nEuroPython 2023 \nLinkedIn \nGitHub\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1d3bbd13-f4c2-48e1-84bd-2d4f7cc5568f": {"__data__": {"id_": "1d3bbd13-f4c2-48e1-84bd-2d4f7cc5568f", "embedding": null, "metadata": {"Section": "Data Science, AI & ML", "Type": "Talks", "Target Audience": "Advanced", "Last Updated": "12 Sep, 2023", "title": "Data Pipelines in Production - Bad vs Best Practices", "speaker": "Bhavani Ravi (~bhavaniravi)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "bb93469c97b971a5a94f82438e3f8fbc95c054cea24ec43a06bdb301ce280c83", "text": "\n\nDescription:\nPipelines are an inevitable part of the Data ecosystem. There are enough tools on the market to implement pipelines. However, as with any technology, there are good and bad ways to use it. \nThis talk will explore the bad and best practices when deploying Data pipelines to a production environment. \nFrom common pitfalls, such as misconfigured tasks and lack of scalability, to best practices, such as robust monitoring and proper security measures, \nThis talk will provide practical advice for anyone looking to implement Data pipelines in their production, with Airflow as an Example.\nPre-Requisties\nTo understand the nuances of the talk, we assume you work with data tools and are aware of Production needs.\nWhat's covered?\nWe will start with a basic data pipelining example, where a developer starts looking for a tool to automate things.\nThe complexity grows from there to something so huge the team starts firefighting \nThere is a better way.\nStarting with the best practices. What checkpoints and assumptions must you have before making things live?\nMove fast and break things, but with caution.\n\n\n\nPrerequisites:\nData engineering and data pipelining\n\n\n\nContent URLs: \nThe talk is based on my blog post \nhttps://dataanddevops.com/apache-airflow-bad-vs-best-practices-in-production-2023\nSlides\nhttps://docs.google.com/presentation/d/1zbqIs5zDIxfLY7_Rre2TQE9XwL23kdkFZHz5Tz7MtQw/edit?usp=sharing\n\n\n\nSpeaker Info:\nBhavani Ravi is an Independent software Engineer who has been in the Python ecosystem for 7 years. She has contributed to Opensource libraries like Pandas and Airflow.\n\n\n\nSpeaker Links:\n\nhttps://www.youtube.com/watch?v=gjUzPGKSuDM\nhttps://www.bhavaniravi.com/about-me/talks\nhttps://www.bhavaniravi.com/about-me/opensource-contributions\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5cfad886-7f8f-4740-af16-7ea1797731d4": {"__data__": {"id_": "5cfad886-7f8f-4740-af16-7ea1797731d4", "embedding": null, "metadata": {"Section": "Networking and Security", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "Speeding up Python with Rust: GeoIP Lookup Database as a case study.", "speaker": "Abhijit Gadgil (~gabhijit)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "99311aa7a960ef6704c8f02ecab2a727bfa976c6652b8cd2ad6881e31f0c89b5", "text": "\n\nDescription:\nIn order to perform GeoIP Lookup, there are databases like maxmind available, which allow one to map an IP address to a given country. In this talk we explore an approach to implement such a database using first principles in Python and then take a look at how this implementation can be speeded up using Rust and Python bindings for the Rust library using pyo3.\nThe talk is organized into following three sections - \n\nOverview of GeoIP Database Lookup Implementation (5 minutes) \n\nInternet, Autonomous Systems and BGP Updates \nPublicly available datasets, to obtain the required data that is - \n\nPrefix data \nAutonomous Systems to Organizations and  Organizations to Country Data.\n\nRouting Table and Longest Prefix Match\n\nImplementation of above routing table and other utils in Rust with available Pythonic APIs and performance comparison (20 minutes)\n\nAn implementation of a Routing Table to perform longest prefix match for an Input IP Address in Python (And using numpy.dtype)\nSame implementation in Rust with Python Bindings \n\npybgpkit_parser (public PyPI package)\nroute_table ( We will discuss in details this implementation)\n\n\nPerformance Comparison of the two approaches (5 minutes)\n\nAudience should expect to understand the following - \n\nUnderstand about how internet works\nBasic implementation of parsing structured data in Python (python struct module)\nSimple implementation of Longest Prefix Match and a routing table.\nAn overview of Rust and pyo3.\n\n\n\n\nPrerequisites:\nNone. This is an intermediate level talk with lot of Python (and Rust) code. The aim is also not to provide a tutorial on pyo3 per se. But we will touch upon enough intro to help understand the code.\n\n\n\nContent URLs: \n\nPublic Datasets\n\nRouteviews for the BGP RIB data\nCaida for Autonomous Systems data. \n\nCode\n\nPython implementation\nRust code with Python Bindings \n\nSlides\n\nSlides\n\n\n\n\n\nSpeaker Info:\nSoftware developer with experience at several layers of abstraction. Python is my GoTo language to experiment with ideas and Rust is my most favorite language. I have been a speaker at previous Pycon India conferences. I work as a freelance software developer through my consultancy company hyphenOs Software Labs\n\n\n\nSpeaker Links:\nLinks to slides for my previous Pycon Talks \n\nCall, Raise or Fold running poker simulations in Python.\nPython and cffi visualizing network traces\n\nSocial Links:\n\nLinked In\nGithub\nBlog\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "bb2fcb57-f81d-43a5-b626-3da620062520": {"__data__": {"id_": "bb2fcb57-f81d-43a5-b626-3da620062520", "embedding": null, "metadata": {"Section": "Culture and Society", "Type": "Talks", "Target Audience": "Beginner", "Last Updated": "12 Sep, 2023", "title": "How I restarted my career by contributing to Open Source?", "speaker": "Bowrna"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "947d3626593a06e3d97b65befb4b3a44ed4c55a8325b769cf719e4aa68c58a2b", "text": "\n\nDescription:\nThis talk is about my experience of restarting my work after taking a career break. I had to take a break after my maternity leave due to increasing stress at work and my physical health was not in good shape. While I wanted a break I was also afraid that I won't be able to start working again. So I made a concrete plan on how I am going to spend my time during the career break and started focussing on the open source project in the little time I got.\nFrom then I got opportunity to secure scholarship and internship in Outreachy programme and worked in Airflow project. That was the turning point and from then I gradually started making more open source contribution to Airflow. It took me about a year to gain momentum and I started checking for part-time opportunity as I have to be the primary care-giver for my kid too. And finally I landed in job that perfectly fits me and here I am pursuing my work that I was afraid that I wouldn't come back. \nIn this talk I will tell about making first contribution to open source, how to make positive impact on open source project and get more out of it, being your own driver and how working consistently in open source pays off.\n\n\n\nPrerequisites:\nThis is a talk to inspire people how they can restart or change into tech career by making contribution to open source software. This gives explanation on guideline about how to choose projects for making the first contribution, career opportunities that opens up after making contribution etc. This will be useful for any person who wants to restart their career after a break.\n\n\n\nSpeaker Info:\nSoftware Engineer Unravel Data, Former Outreachy Intern for Apache Airflow\nBowrna is a self-taught programmer who started building software after a non-CS degree. With the experience of about 10 years, She thinks she has learned only a drop in ocean and wants to explore more. She is an active open-source contributor to the Apache Airflow project and works on solutions to monitor pipelines in her day job\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "16b41630-e798-4d98-b013-8860e7b0f31f": {"__data__": {"id_": "16b41630-e798-4d98-b013-8860e7b0f31f", "embedding": null, "metadata": {"Section": "Data Science, AI & ML", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "The Why Conundrum - Practical causal inference and discovery with python", "speaker": "dineshVenkatesan"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "c5279947aa390f1d9c6cc4a3fee25a61cb29323b903f7fc6509205a37a3fe070", "text": "\n\nDescription:\nWhen we process raw data, it transforms into \"information\", and when information is processed, we get \"knowledge\" and when knowledge is processed, we get \"wisdom\". In this journey, the question \"why\" acts as the compass that guides a statistician to travel from mere knowledge land to profound understanding. \nIn this talk, we will take a hands-on and practical approach towards explaining the concepts of Causal Inference and Discovery with python. \nIn this talk's context, Causal Inference is the process of applying data science/ML libraries along with CI libraries such as doWhy and econML to determine whether a change in one attribute causes a change in another thing. This is a generic deduction process moving from generics to specifics. \nCausal Discovery is the process of applying data science/ML libraries to identify and explore causal relationships without prior hypothesis. This is a induction process moving from specifics to generics. We will highlight how we can use observational data and analyze it with domain knowledge to come up with causal models.\nIn the spirit of Plausible reasoning, the theme of this talk will be the following:\n\"Experience modifies beliefs. \nA sentinel being learns from experience. \nA good scientist endeavors to extract the most correct belief from a given experience\u201d\nIn the demo section:\nWe will show case the open source python libraries being applied on practical causal experiments to answer questions such as:\n1. Why does a computer system get infected by a virus?\n2. Why was a virus not able to infect a system running a particular software?\n3. Why is a software running sluggishly? \nand we will empower the audience with the practical knowledge to use the framework to use against their own data corresponding to the problem domain they are working on to answer causal questions.\nIn the process, we will also cover Prof. Judea Pearl's ladder of causation and explorer Pearlian perspective of causal inference and discovery with dowhy calculus.\n\n\n\nPrerequisites:\nThe session will cover everything that needs to be known to understand the concepts.\nBasic statistical inference concepts\nBasic programming concepts\nBasic Numpy, Scipy knowledge is prefered\n\n\n\nContent URLs: \nhttps://malwareresearch.medium.com/the-curious-case-of-app-collusion-81b702266098\nhttps://malwareresearch.medium.com/curious-connections-ad3aaa9f5413\nhttps://malwareresearch.medium.com/context-bias-deep-learning-84f2447f4f26\n\n\n\nSpeaker Info:\nDinesh Venkatesan is a Logician & Mathematician presently working as security researcher at Microsoft. He has been in the cyber security industry for over 17 years working with Google, Symantec and HCL Technologies and has published numerous blog posts on malware analysis. He is a specialist on the mobile threat landscape and desktop security threats and has discovered multiple vulnerabilities in Android framework layer, responsibly reporting it to Android and helping to make the OS secure. He has hands-on expertise in writing generic detection and cure routines for prevalent malware families. He is on an active lookout for collecting threat intel about sophisticated attacks and keen on researching various threat actors and developing useful insights into malware evolution.\n\n\n\nSpeaker Links:\nRSA conference : https://www.rsaconference.com/experts/dinesh-venkatesan\nAndroid Security Summit: https://android.ins.jku.at/symposium/2020/program/dinesh-venkatesan-and-aditi-bhatnagar/\neBPF Summit 2020: https://www.youtube.com/watch?v=Sun0bWGVl_o\neBPF Summit 2022: https://www.intel.com/content/www/us/en/developer/articles/community/highlights-from-the-ebpf-summit-2022.html\nMicrosoft blog: https://www.microsoft.com/en-us/security/blog/2020/10/08/sophisticated-new-android-malware-marks-the-latest-evolution-of-mobile-ransomware/\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b19a6d8f-f55d-4cff-998a-944b9f0cac43": {"__data__": {"id_": "b19a6d8f-f55d-4cff-998a-944b9f0cac43", "embedding": null, "metadata": {"Section": "Core Python", "Type": "Talks", "Target Audience": "Beginner", "Last Updated": "12 Sep, 2023", "title": "Amaze your friends by painting images on Google Sheets using Python", "speaker": "Shashi Jeevan M. P. (~shashi3)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "5de859bbdde566c16dd52f22288a29e60ae7e2aa07c6d2512813cb043d4de475", "text": "\n\nDescription:\nHave you ever wondered how you could paint images in a Google spreadsheet?\nCan you paint existing images in the Google sheet with accurate colors?\nCan you do this by simply running a command and painting ANY pictures?\nGoogle spreadsheet is popular as a data storage tool. Many open-source libraries are available for manipulating the data in Google Spreadsheets. These include\n\ngsheets\npygsheets\ngspread\n\nBut, these have limitations when using Google Spreadsheet as a canvas, which I will describe in the session.\nI had to build a custom library on top of the Python library provided by Google.\nIn this session, I will describe how to use Python for\n\nSetting up Google Sheets as Canvas, \nReading image data and \nUsing raw Google Spread Sheets API to generate requests and update the sheet with Image pixel data.\n\nI will share the learning from using Python DataClasses to reduce code complexity and handle large images.\nThis work can be extended further to generate custom graphics and render on Google Sheets.\n\n\n\nPrerequisites:\nBasic knowledge of\n\nPython language\nGoogle Sheets\nJSON\n\n\n\n\nVideo URL:\nhttps://youtu.be/H2J7bXMvqL4\n\n\n\nContent URLs: \nPresentation Link\nhttps://docs.google.com/presentation/d/1MxHmHFKf3bpcK8ellfRt1naehDsdDjWOglKi91oiiH8/edit?usp=sharing\nSource Code Link\nhttps://github.com/shashijeevan/ImageToGoogleSheet\n\n\n\nSpeaker Info:\nShashi Jeevan has over 25 years of experience in the software industry. He is a Certified Ethical Hacker (Practical). He is an Inventor of the US Patent (Number: 6,609,084, Issue Date: August 19, 2003). He is Vice President of Delivery and Deployment at Tekfriday Processing Solutions Pvt. Ltd. Where he is responsible for DevOps, Cloud, and Security. He is the founder of the Hyderabad Software Architects meetup group. He likes to tinker with technology and share his learnings. He has experience in presenting in multiple technical talks with large audiences. He has been using Python for various projects for more than 15 years.\n\n\n\nSpeaker Links:\nMy Blog on the topic\nMy Personal Blog\nMy LinkedIn Profile\nMy Previous presentations\n\nGlobal Azure Bootcamp 2018 \nTopic: Introduction to Deep Learning on Azure\nDescription:\nI have presented the fundamentals of Machine Learning and Deep Learning. Then demonstrated the training of the MNIST model using Keras with Jupyter Notebook on Azure VM. Later, I used a Flask App to detect the live hand-drawn digits using the trained model. I blogged about my experience of presenting. \nEvent Link: https://themugh.github.io/gabc2018 \nSlides: https://www.slideshare.net/shashijeevan/introduction-to-deep-learning-on-azure-global-azure-bootcamp-2018-95267374\nGlobal Azure Bootcamp 2019 \nTopic: Azure Kubernetes Service\nDescription:\nI have presented the fundamentals of Docker and the need for Kubernetes. Then demonstrated the setup of managed Kubernetes using Azure Kubernetes Service. Later demonstrated scaling the cluster using kubctl. \nEvent Link: https://themugh.github.io/gabc2019/ \nSlides Not Available.\n\nMy Meetup group \nHyderabad Software Architects  (https://www.meetup.com/Hyderabad-Software-Architects/) \nI am the founder and organizer of this meetup. I have also presented sessions on Microservices, Cloud, Python, Machine Learning etc. \nI have also got experts in the field to give sessions to improve collaboration among the Software Architects in Hyderabad.\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "65df0eb8-704c-43b5-9f67-82cd3536d415": {"__data__": {"id_": "65df0eb8-704c-43b5-9f67-82cd3536d415", "embedding": null, "metadata": {"Section": "Scientific Computing", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "How Differential Privacy Changed The World, and What The Math Really Means", "speaker": "Rumanu Bhardwaj (~rumanu)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "7a7d537a756023e630f19101f84587976631858d440ceaadb9766c1000510c15", "text": "\n\nDescription:\nA walkthrough how differential privacy became the industry standard for data privacy, pointing out the mathematical elements ensuring this robustness.\n[7 Minutes] Exploration of how personalized permission marketing advertising systems created the need to protect consumer privacy\n[4 Minutes] The technical definition of Differential Privacy\n[7 Minutes] Exploration of the mathematical components of Differential Privacy\n[5 Minutes] A brief discussion of approximations of Differential Privacy and when to use them\n[2 Minutes] Examples in Python Libraries that can be used to implement DIfferential Privacy, e.g. PyDP\n[5 Minutes] Q&A\n\n\n\nPrerequisites:\nFamiliarity with statistical distributions and python programming is recommended to the participants.\n\n\n\nSpeaker Info:\nRumanu is deeply passionate about bringing privacy to data infrastructures globally, and studies the intersection of laws in that regard with privacy preserving technologies and their integration to reccommender systems and customized advertising. She was born a data scientist in the circuit via PyData and other developer circle meetups and likes to be involved with the community at large. She is excited to be a first time in person PyCon India speaker and connect with the community.\n\n\n\nSpeaker Links:\nhttps://pyvideo.org/speaker/rumanu.html\nhttps://twitter.com/festusdrakon\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4f296b2a-9a76-4d39-8bc2-c9aecd571c2d": {"__data__": {"id_": "4f296b2a-9a76-4d39-8bc2-c9aecd571c2d", "embedding": null, "metadata": {"Section": "Scientific Computing", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "12 Sep, 2023", "title": "Complex Network Analysis in Economics", "speaker": "Navya Agarwal (~navya7)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b860d4b535effe0d971d9bb4e7a341ad4aa26327962a321ab04d5f3488e98d1f", "text": "\n\nDescription:\nIn recent years, there has been more and more interest in studying economy-related questions by means of network science. A reason for this interest builds on the realization that the economy's behavior cannot be investigated by individually studying the constituting components but only by considering the interplay between all relevant parts. This is in strong contrast to the standard economic theory.\nIn this talk, we will understand how network science helps to explore and analyze economic phenomena at varying scales and granularity.\nWorld trade is generally highlighted as the largest economic network. We will analyze it in detail using NetworkX and really understand the significance of various network measures.\nTalk Outline:\nA. Introduction to Complex Network Analysis\nB. Why Network Analysis in Economics?\ni. Understanding interconnected economic components\nii. The significance of structural interdependencies\niii. Types of Economic Networks\nC. World Trade Analysis using NetworkX\ni. Utilizing the BACI-CEPPI dataset for bilateral trade relations\nii. Constructing the World Trade Network Graph\niii. Geographic visualization vs. topological visualization\niv. Analyzing network density and heterogeneity\nv. The power-law distribution and its impact on global trade fluctuations\nD. Centrality Measures and Clustering\ni. Identifying influential countries with centrality measures\nii. Revealing Regional Trade Blocs with clustering\nE. Analyzing Trade Networks of Different Commodities (Natural Gas, Coffee, Diamonds)\n\n\n\nPrerequisites:\n\nPython Programming Skills\nFamiliarity with Social Networks\n\n\n\n\nSpeaker Info:\nNavya Agarwal is a third year Computer Science student at IGDTUW. She has worked on NetworkX as an Outreachy intern. She is currently researching Coordinated Campaigns on Social Media using complex network analysis. She is passionate about Open Source, specifically the scientific python ecosystem.\n\n\n\nSpeaker Links:\nPersonal Website\nGitHub\nLinkedIn\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "65837819-e65f-49d4-8c11-190b152c4287": {"__data__": {"id_": "65837819-e65f-49d4-8c11-190b152c4287", "embedding": null, "metadata": {"Section": "Embedded Python and IOT", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "19 Sep, 2023", "title": "Accelerating testing cycles of embedded devices using Python", "speaker": "madhuri anagal (~madhuri1)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "898036824923c70d3c04831970b2fec821ebf9924a1dd00394d35ffa312582fd", "text": "\n\nDescription:\nThe talk addresses how the Python ecosystem of tools can be used to develop test automation framework for embedded devices where high speed data acquisition is needed. The test automation framework provides a solution for cataloging, retrieving, and analyzing the captured sensor data from embedded devices\nThe embedded Device Under Test(DUT)  can be any device that works on serial communication, that is used for precise control and positioning applications, such as, aerospace and smart ammunition. But generally, it can be any embedded device that has sensors that transmit data up to 5MBps Baud rate. The framework is designed to perform functional and endurance testing. This aids in early detection and reporting of issues in the DUT and reduces SDLC duration. The framework uses techniques to receive high speed data transmitted by the DUT, while maintaining zero data loss and write it to file-system on Host system. \nPython's simplicity and readability will be showcased, emphasizing how it eases and accelerates the software development process. Participants will discover how Python provides various libraries that facilitate the interaction with embedded devices, and enables efficient analysis, transformation, and visualization of sensor data.\nOutline of the talk:\n\nBackground: Brief introduction of test automation framework, DUT, Testing Life Cycle\nTechnology stack: Important python libraries used, Robot framework \nChallenges faced: Data loss management, longer testing cycles \nLessons learnt: How various Python libraries can be used to optimize testing time and detect issues in DUT at the earliest\nEpilogue: Future scope, Q&A session\n\nLink to Presentation: https://docs.google.com/presentation/d/1Y6DT69r3ZnsvEVNzSkli6-TaJ8-kvBrn/edit?usp=sharing&ouid=110936154572625701821&rtpof=true&sd=true\n\n\n\nPrerequisites:\nBasic knowledge of embedded systems\n\n\n\nSpeaker Info:\nI am working as senior Python developer at Acclivis technologies,Pune. I have experience of developing test automation frameworks for embedded devices and for automotive devices using Python , Robot framework and Jenkins\n\n\n\nSpeaker Links:\nwww.linkedin.com/in/madhurianagal\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5aea78b6-7b3f-4330-90b5-d43bf067299d": {"__data__": {"id_": "5aea78b6-7b3f-4330-90b5-d43bf067299d", "embedding": null, "metadata": {"Section": "Developer tools and automation", "Type": "Talks", "Target Audience": "Intermediate", "Last Updated": "24 Sep, 2023", "title": "Zero-Copy Zen: Boost Performance with Memory View", "speaker": "Kesia Joies (~kesia)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "b4a55a334c9f5ff8215e5f279bc077d4c7e027681f0edddb14705bfe35f3e33d", "text": "\n\nDescription:\nAre you tired of struggling with memory management in Python? Do you want to take your skills to the next level and achieve maximum performance while minimising memory usage? Look no further, here is Zero-Copy in Python! Zero-copy is a technique in computer programming that allows data to be transferred between different parts of a program without being copied to intermediate buffers. In Python, this technique can be achieved using the memory view object, which provides a view into the memory of other objects. Learn how to efficiently manipulate large datasets and optimise your code with the help of this powerful tool. Whether you're working with sockets, objects or memory profiling, memory view is your key to faster and more efficient Python programming.\nIn today's data-driven world, efficient memory management is critical for achieving optimal performance in Python. Memory view and byte array provide a powerful combination of tools for managing bytes and memory in Python, enabling zero-copy interactions that can significantly improve performance and reduce memory usage.\nMemory view is a built-in Python class that provides a zero-copy interface to the memory of an object, allowing efficient manipulation of large data sets. Memory view objects can be used to share memory between different parts of a program without creating intermediate copies of the data, which can significantly improve the performance of Python code. This feature is particularly useful when working with large arrays, binary data, or network programming using sockets. Memory view can also be used in conjunction with the buffer protocol to work with objects in a zero-copy manner. Overall, memory view is a powerful tool for Python developers looking to optimise their code and improve performance. \n\nOutline of the talk:\n\nUnderstand what is Zero-Copy\n\nCompare traditional mechanism with zero-copy of sending file\nLook into Python example of each mechanism\nos.sendfile() and it's zero-copy implementation\n\nPython's bytes()\n\nBasic syntax and examples\n\nPython's bytearray()\n\nBasic syntax and example\n\nIntroduction to Memory View\nUnderstand buffer protocol\nDive into Memory View features\n\nComparison of memoryview() performance\nApplications & Benefits\n\n\n\n\n\nPrerequisites:\nPython knowledge\n\n\n\nSpeaker Info:\nKesia Mary Joies is a passionate Python developer, currently working as a Product Engineer in UST. She enjoys leveraging logical thinking to develop software solutions that make people's lives easier. At present, she is focused on developing Strollby - a travel platform that utilises Python microservices with GraphQL backend. She was awarded the Grace Hopper Scholarship for the year 2021, awarded annually to women in Technology. Also, she was recognised recently as the Top 5 Best Women Outgoing Students from India, conducted by IEEE Pune Section and Hope Foundation India. She was a speaker in PyConf Hyderabad 2022, and embarked on her journey as an International speaker at the oldest and longest running volunteer-led Python programming conference, EuroPython Conference 2023.\n\n\n\nSpeaker Links:\nLinkedIn\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1e264a40-fe2f-4c0f-954b-32427f471b0a": {"__data__": {"id_": "1e264a40-fe2f-4c0f-954b-32427f471b0a", "embedding": null, "metadata": {"Section": "Data Science, AI & ML", "Type": "Workshops", "Target Audience": "Beginner", "Last Updated": "14 Sep, 2023", "title": "Mastering Retrieval Augmented Generation (RAG) with LlamaIndex and LLMs", "speaker": "ravi theja (~ravi1)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "e14d7553deeccb8ea1d62416410198657cc8a709cd7f41f92b81101b1fea34fe", "text": "\n\nDescription:\nLlamaIndex is a toolkit designed to enhance the utility of Large Language Models (LLMs). It provides powerful capabilities to bridge the gap between your custom data and LLMs, thereby enabling the construction of sophisticated, data-driven applications. With LlamaIndex, harnessing the potential of retrieval and generation in language models becomes seamless and efficient.\nIn this hands-on workshop, we will dive into the intricacies of the Retrieval Augmented Generation (RAG) paradigm, demonstrating how it can be leveraged to build potent systems such as Q&A systems, chatbots, and data agents. A core component of our session will be the exploration of LlamaIndex as an essential bridge between LLMs and your custom data, equipping participants with the knowledge to craft tailored applications efficiently. Here is the outline of the workshop.\nIntroduction\n\nBrief on Large Language Models and LlamaIndex.\nOverview of the Retrieval Augmented Generation (RAG) paradigm\n\nUnderstanding RAG Paradigm\n\nDetailed explanation of RAG and its applications\nHow RAG enhances Large Language Models with custom data\n\nMastering Indexing and Querying Techniques\n\nPreparing a robust knowledge base using LlamaIndex's data connectors\nand indexing capabilities\nUnderstanding the retrieval process for the most relevant context\ngiven a user query\nSynthesizing responses using LLMs and LlamaIndex for effective\nquerying\nPractical demonstration and hands-on practice of these techniques\n\nWorking with Advanced Building Blocks\n\nPractical experience with retrievers, node postprocessors, and\nresponse synthesizers\nUnderstanding the use of these tools in different applications\n\nRouter Engines\n\nIntroduction to Router Engines as decision-making systems in\nLlamaIndex\nChoosing the right query engine/index based on user\u2019s query\n\nEvaluation\n\nResponse Synthesis Evaluation.\nResponse + Context Evaluation.\nQuestion Generation and Evaluation.\n\nExploring Data Agents\n\nUnderstanding Data Agents and their role in interacting with data\nDynamic interaction with external tools using Data Agents\n\n\n\n\nPrerequisites:\n\nPython and Experience with Large Language Models (LLMs)\nParticipants should have a fundamental understanding of Python programming and prior experience with Large Language Models such as ChatGPT, which will provide a basic comprehension of LLM workings.\nAccess to Google Colab\nOur sessions will be conducted using Google Colab, so please ensure you have access to this platform.\nOpenAI API Key\nWe'll be utilizing GPT-based models by default for building applications with LlamaIndex, so having an OpenAI API key will be essential.\n\n\n\n\nVideo URL:\nhttps://www.youtube.com/watch?v=7H7sNDg6j34\n\n\n\nContent URLs: \nHere is a version of the slides for the workshop. Notebooks for each section will be updated after the proposal acceptance.\n\n\n\nSpeaker Info:\nI am an Open Source Contributor at LlamaIndex and Senior Data Scientist at Glance (Inmobi).\n\nContributed different data loaders and evaluation modules to LlamaIndex.\nBuilt Recommender Systems, NLP, and GenAI applications at Glance. I am part of Glance TV team which is a product built entirely using LLM's and vector DB's. Demo\nI have published papers at ACL and COLING workshops.\nI have given talks about LlamaIndex at the Hasgeek GenAI meetup, Fifth Elephant Conference, Analytics Vidhya Data Hack Summit, and different VC firms (Accel, Together, Speciale).\nPublished blogs and videos on LlamaIndex.\nRecognised as Top 5 GenAI Experts in India by Analytics Vidhya at Data Hack Summit.\n\n\n\n\nSpeaker Links:\nLinkedin\nTwitter\nGithub\nMedium\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8ba2c171-2221-40d8-ad8d-331cf9ecaa9f": {"__data__": {"id_": "8ba2c171-2221-40d8-ad8d-331cf9ecaa9f", "embedding": null, "metadata": {"Section": "Blockchain", "Type": "Workshops", "Target Audience": "Intermediate", "Last Updated": "14 Sep, 2023", "title": "Python + Blockchain: Your Guide to Building Full Stack DApps", "speaker": "laisha wadhwa (~laisha3)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "2d8324377fc9396b60d20890666da33fd3d214c6cae8594e7514ba448b7152c5", "text": "\n\nDescription:\nAre you ready to dive into the fascinating world of decentralized applications (DApps) and leverage the power of Python to build your own blockchain-based application? Join me for an exciting workshop where I will guide you through the entire process of building a Full Stack DApp using Python, smart contracts, web3.py, and Flask!\nIn this hands-on workshop, you'll learn how to combine the frontend and backend components of a DApp to create a seamless and decentralized user experience. We'll start by understanding the fundamental concepts of DApps and how they differ from traditional applications. Then, we'll explore the role of smart contracts and their significance in the blockchain ecosystem.\nTopics to be covered:\n\nIntroduction to DApps and Smart Contracts\n\nUnderstanding the architecture of DApps\nExploring the role of smart contracts as backend code on the blockchain\nDeploying smart contracts to Ethereum (or other compatible blockchains)\n\nPython and web3.py\n\nGetting started with web3.py and its functionalities\nInteracting with Ethereum blockchain using Python\nSending transactions, reading contract data, and managing accounts\n\nBuilding the Frontend with Flask\n\nSetting up a Flask server for the frontend\nImplementing user interfaces to interact with the smart contract\nHandling responses and displaying blockchain data on the frontend\n\nIntegrating Frontend with Backend (Blockchain)\n\nConnecting the Flask frontend to the deployed smart contract\nCreating interactive forms and components for user interactions\nExecuting transactions and fetching data from the blockchain in real-time\n\n\nBy the end of this workshop, you will have gained a comprehensive understanding of DApp development with Python and web3.py. You'll be equipped to build your own Full Stack DApps, interact with Ethereum's smart contracts, and harness the power of blockchain technology to create decentralized applications.\nDon't miss this opportunity to be part of an engaging and practical workshop where you'll unlock the potential of Python in the world of blockchain development. Let's come together and explore the exciting possibilities of building decentralized applications!\n\n\n\nPrerequisites:\nPre-requisites:\n- Basic knowledge of Python programming language\n- Familiarity with web development concepts (HTML, CSS, JavaScript)\n- Some understanding of blockchain and Ethereum is a plus, but not mandatory\n\n\n\nContent URLs: \nhttps://medium.com/@laisha.w16_85978/ethereum-vs-polygon-the-ultimate-comparison-2fb479fe61cf\n\n\n\nSpeaker Info:\nHey there! I'm Laisha Wadhwa!\nI'm incredibly excited about the world of technology and its potential to create positive change. As the head of Devrel (Developer Relations) at Pesto tech, I get to engage with brilliant minds in the tech community, fostering connections and helping developers reach new heights.\nBefore joining Pesto, I was working as a Senior Software Developer at Goldman, where I worked on building consumer banking products and dealt with security and risk aspects of fintech. My passion for Data and Machine Learning led me to explore innovative ways to leverage these technologies for solving real-world problems. However, my journey doesn't stop there. I've been completely captivated by the possibilities that the world of Web3 brings to the table. Building upon my experience, I'm enthusiastically pushing the boundaries of decentralized technology, envisioning how it can transform society and empower individuals like never before.\nOne of my proudest achievements is the development of RadarFi, a cutting-edge security product that helps protect users in the digital realm. My drive to create tech for social good has been a guiding force throughout my career, and I'm committed to using AI and other groundbreaking technologies to usher in the next generation of revolution.\nBeyond my technical expertise, I have ventured into the realm of public speaking, podcasting, and technical writing. Sharing knowledge and insights with the community is something I'm incredibly passionate about, and it gives me immense joy to contribute to the growth and learning of others. As a community builder, I firmly believe in the strength of collaboration and mutual support. I strive to create spaces where like-minded individuals can come together, share ideas, and collectively drive innovation.\nIn a world that is constantly evolving, I find solace in exploring the vast potential of emerging technologies. I'm an unapologetic tech enthusiast with an insatiable curiosity for what lies ahead.\n\n\n\nSpeaker Links:\nBlog: https://medium.com/@laisha.w16_85978\nNewsletter: https://web3bitsnbytes.substack.com/\nPrevious Talks:\nPydata Global, WWCode Podcast, BlockDataPy Summit\nLinkedIn | Twitter | GitHub\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "aea2acc5-0108-488e-8153-35b886a8f53a": {"__data__": {"id_": "aea2acc5-0108-488e-8153-35b886a8f53a", "embedding": null, "metadata": {"Section": "Web & App development", "Type": "Workshops", "Target Audience": "Intermediate", "Last Updated": "14 Sep, 2023", "title": "Let's have fun building APIs with Starlette: The Asynchronous Python Web Framework", "speaker": "hemi s.k (~hemi)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "eb9185da1d6b96a80eebe179bc1f6bf20f63da013e189e943da636ddd7b3af2b", "text": "\n\nDescription:\nThis workshop will help one get started with Starlette; we'll go through each fundamental component of the framework starting with the basics to give a complete understanding of its capabilities. This workshop will walk one through Starlette, an ASGI web framework as well as a toolkit that can help in building asynchronous web services and applications. I'll rapidly get you up to speed in this comprehensive workshop by guiding you through the framework from beginning to end! Whether you are interested in expanding your current craft, want to change careers or simply wanting to learn a very popular topic, then this workshop is for you! \nStarlette has everything needed for creating state of the art APIs and web applications with ease. Build for performance from ground up Starlette offers everything that one can expect from a modern framework: fast development, steep learning curve, concise documentation and more! By the end of this workshop, one would have built an async web application! And best of all, each and every concept discussed will be implemented in code. This will not only be a theoretical workshop, but a workshop that builds both knowledge and experience. Whenever we introduce a concept, we will implement it in code so that one gets to see how it works in practice.\n\n\n\nPrerequisites:\nPython\nRest APIs\n\n\n\nContent URLs: \nPresentationLink\nGithub\n\n\n\nSpeaker Info:\nI work as a Senior Software Engineer at Epam Systems, I am always down to get my hands dirty in the code. Extremely passionate about teaching in general. In my free time, one can find me hitting the gym, reading books, or watching \"Young Sheldon.\"\n\n\n\nSpeaker Links:\nGithub link\nPycon Italy 2023 Speaker \n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e32c921a-fdab-4579-a928-d5e8159d4a2f": {"__data__": {"id_": "e32c921a-fdab-4579-a928-d5e8159d4a2f", "embedding": null, "metadata": {"Section": "Data Science, AI & ML", "Type": "Workshops", "Target Audience": "Intermediate", "Last Updated": "14 Sep, 2023", "title": "All Them Data Engines: Pandas, Spark, Dask, Polars and more - Data Munging with Python circa 2023.", "speaker": "shaurya shaurya3 (~shaurya3)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "a099e4fe75a2ffd88f392343370573366cc0f1bfcf846264ac07c451ddfd17ee", "text": "\n\nDescription:\nIntroduction\n\nVersatility. / \u02ccv\u025cr s\u0259\u02c8t\u026al \u026a ti /  noun: ability to adapt or be adapted to many different functions or activities.  \n\nOften our ecosystems limit us to one technology stack/framework/solution that we end up working on day-to-day. Maybe because the framework was chosen for us, maybe it's the one available at hand, maybe that's the skill most prevalent in the team, maybe it was chosen by following a decision analysis process, maybe other vagaries of the workplace were in play.   \nThis is incredibly limiting in developing an intuition for problem solving, exploring the possibilities and simply being able to use the right tool for the right job.     \nIn trying to gain experience on a new framework on our own, we are inundated with myriad concepts, jargon and \"technical evangelism\" so much that getting to the practical stuff often becomes an uphill battle for most of us.   \nThis workshop aims to address this fundamental issue: \n 1. Get hands-on experience across some of the most in-demand data engineering frameworks around today - Pandas, Spark, Dask, Polars etc. \n 2. Focus on the one core thing - data munging - shaping data, analyzing it and deriving insights.   \nIn this interactive 3-hour workshop, fellow data engineers will explore and gain practical experience with some of the industry's most sought-after data engineering frameworks. Through a series of engaging exercises and real-world-like examples, fellow attendees will be empowered to tackle data engineering challenges efficiently and effectively.  \nPrerequisites: Low barrier to entry\nThe workshop uses Jupyter Notebooks (use Anaconda installation locally or Google Colab), GitHub (for collaborations, questions, discussions etc.) and popular datasets (everyone likes movies - we use the MovieLens dataset here for several practical exercises).  \nYou should have basic familiarity with Python and Jupyter.   \nEither have a working installation of Anaconda (or any of it's flavors - miniconda, mamba, others) or have access to Google Colab. While you can also use Binder, I have not tested the notebooks on it.  \nTalk Outline and Approach\nThe full workshop (WIP at the time of this proposal submission - openly available on Github) will be based around \"Problem Sets\" - practical questions that we'll ask about the data, then try to answer these questions using the data engineering frameworks.   \nThe workshop will have the following sections, 25 to 30 minutes each: \n1. Pandas \n2. Spark \n3. Dask \n4. Polars \n5. (Optionally, if time permits) - Apache Arrow DataFusion and Ray   \nThis will ensure we cover a wide gamut of how to think about distributed computing problems, the different strengths and weaknesses of each of these data engineering systems and aim to build a level of comfort and familiarity with the various systems so that investigating further or picking up a new system in future becomes far easier than it is today.  \nContinually Evolving\nThe intent is to keep this workshop evolving, keeping up with the fast in flux data engineering field.  \nThe open GitHub repo will carry a full list of references, as well as sidebars - that capture lessons big and small that we encounter solving problems.   \nWhile the session will be over in 3 hours, the collaboration can continue as we can all fork the repo, contribute PRs, submit questions and issues etc. My aim is to keep adding more notebooks for all emergent data engineering systems that I feel may be important. So we'll all have a resource on GitHub that will continue to generate value long after our 3 hour session is over.  \nTakeaways\nBy the end of this workshop, fellow participants will have a understand the core concepts behind these frameworks and their applications. They will be equipped with practical skills and techniques to efficiently manipulate, process, and analyze data using Pandas, Spark, Dask, Polars etc. \nThe most important takeaway? Valuable insights into selecting the right framework for the right job.\n\n\n\nPrerequisites:\n\nWorking know-how of Python, some familiarity with GitHub\nWorking installation of Anaconda or any similar distribution (prefer - public, open, free) or access to Google Colab\nOptionally - working installations of Pandas, pySpark, Dask and Polars - this to ensure minimal time is wasted in 'set-up' related tasks. The current notebooks on GitHub already carry instructions for installation.\nPossibly a working internet connection - just so we can access the data and collaborate on Github\n\n\n\n\nContent URLs: \n\nGithub repo for the workshop (Jupyter Notebooks): https://github.com/shauryashaurya/learn-data-munging\n\n\n\n\nSpeaker Info:\nShaurya Agarwal, Deputy Head - Engineering, at Barnes and Noble (BNED LoudCloud). \nWith 20+ years of experience in Analytics & ML, Big Data and Cloud Computing, Shaurya is leading the engineering teams at BNED that are working on building the next generation of data products for the company.\n\n\n\nSpeaker Links:\n\nGithub: https://github.com/shauryashaurya\nLinkedIn: https://www.linkedin.com/in/shauryashaurya/\nTwitter: @shauryashaurya (https://twitter.com/shauryashaurya)\nTalks:\n\nRecent panel discussion at DataOps Observability Conf 2023: https://www.youtube.com/live/GM1EzNChtdk?feature=share&t=2884\nPanel discussion at Ashnik's Data Pipeline & Observability Insights conference 2022 (https://www.ashnik.com/events/bfsi-datapipeline-and-observability-platform-event-mumbai-india/). This was a invite-only event (CxO layer and leadership of some of India's largest Banks and open-source technology companies were in attendance), but there's a video with highlights: https://youtu.be/mAulCd-XJLU?t=352\n\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "fcdd1f43-a1fa-49f9-8734-e5448d09fe34": {"__data__": {"id_": "fcdd1f43-a1fa-49f9-8734-e5448d09fe34", "embedding": null, "metadata": {"Section": "Core Python", "Type": "Workshops", "Target Audience": "Beginner", "Last Updated": "14 Sep, 2023", "title": "From Novice to Virtuoso: Mastering Object-Oriented Python in 3 Hours", "speaker": "vivek keshore (~vivek17)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "3aae90d1c4818898f5ab23f26425dd3c00d8117b756fabbc6a4ebaa726884c84", "text": "\n\nDescription:\nObject-Oriented Programming is one of the most popular method of modern software development, yet it is one of the most misunderstood concept. Everyone knows the words and definition of popular words like Abstraction, Polymorphism, Inheritance, and encapsulation, yet very few can actually explain beyond book definition or implement these in real world scenarios. The objective of this workshop is to cultivate the Object-Oriented Design thinking, and eliminating all the misunderstandings around the Object-Oriented paradigm.\nThis 3-hour immersive workshop unveils OOP's significance, principles, design thinking and advantages through Python.\nOOP empowers developers to conceptualise real-world entities as objects. This leads to modular, reusable code that can simplify the collaboration. Participants will be able to develop the object oriented design thinking and fundamentals of some of the object oriented principles. Properties, methods, and magic methods enable dynamic object manipulation, streamlining development. The workshop delves into these features, empowering participants to harness Python's potential.\nThe basic understanding of relationships among objects not only enables to develop a right design, but also makes it less error prone and becomes intuitive in later stages of development. As per my experience, the basic root cause of all fundamentally wrong design is not having clear understanding of all the different types of relationships that the objects have with each other. The workshop also aims to give a formula that will help in developing and implementing the right design.\nOnce the relationships are well understood, then the workshop will focus more on the advanced topics. The magic methods gives immense power to the developer that would bend everything as per will. The workshop will explore the power of magic methods, and demonstrate how these magic methods can be harnessed to unleash the unlimited potential, thats limited to only developer's imagination. The workshop will demonstrate the practical uses and implementation of class based decorators, generators, context managers and much more.\nThe workshop will eventually steer towards advanced, yet fundamental topic - SOLID principles. \nSOLID design principles are the cornerstone of robust design, form a pivotal part of the workshop. The workshop is designed to explain each principle with real life examples, implementation and hands on live coding.\nIn essence, this workshop merges theoretical understanding with practical skill development. By elucidating the demand for OOP, explicating its advantages, and delving into Python's OOP capabilities and SOLID principles, participants gain the expertise to construct intricate, adaptable software solutions effectively.\nWorkshop Details:\n1. Introduction to OOP and its significance in software development. (30 mins)\n\nUnveiling Python's core OOP concepts: classes, objects, methods, attributes, and more\nEliminating the misunderstandings around the words - encapsulation, abstraction, inheritance, and polymorphism\nThinking in Object Oriented way\n\n2. Understanding Object Oriented relationships and design formula (30 mins)\n\nUnderstanding various types of relationships\nFormula for thinking/developing object oriented design\nReal life examples and designing the scenarios live\n\n3. Diving into OOP Features (60 minutes)\n\nIn-depth exploration of Python's OOP features\nclass based properties, class based decorators, class based generators, class based context managers, and more\nUnleashing and realising the magic of magic methods\nAbstract classes - The turbo engine of object oriented design.\n\n4. SOLID design principles and implementation (50 minutes)\n\nEmbracing the SOLID principles for robust and maintainable design.\nPractical case studies and real-world examples to reinforce design concepts.\n\n5. Conclusion, Discussion and QnA (10 mins)\n\nPeer review and discussion of the developed application, highlighting design choices and principles.\nRevisiting all the Key Take Away points quickly like revision cards\nQnA, suggestions and feedback from the participants.\n\n\n\n\nPrerequisites:\nBasic knowledge of Python.\n\n\n\nSpeaker Info:\nI am a Python Enthusiast who loves building software applications and education related content. I am a technology professional and a passionate programmer with 11 years of experience in Python & Python related technologies. I am currently working as Architect at SenecaGlobal Inc, Hyderabad. \nI have been involved with multiple professional projects in various industrial domains and technical fields. My expertise is in application development, data processing & analysis, data structures, & algorithms, various non-relational and relational databases, Python, Flask, FastAPI, Celery, RabbitMQ, Redis, Cassandra, AWS, Airflow, and various other tech stacks. I am also an open source contributor, and published self developed libraries on PyPI. I love creating libraries and various utility tools that help me in solving a challenge/problem that could also be used by others in the developers community.\nMy personal interest is in exploring new technologies, web application development, IoT systems, spread Python education, and read novels. I also write and share my thoughts occasionally on Quora and Medium.\n\n\n\nSpeaker Links:\nPrevious Proposals\n\nhttps://in.pycon.org/cfp/2021/proposals/hows-the-job-title-quantum-computer-programmer~bmZQr/\nhttps://in.pycon.org/cfp/2021/proposals/one-api-to-rule-them-all-config-based-development~en5rE/\n\nPyPI Libraries\n\nFlask-Dantic - Library to integrate Pydantic with Flask\nLazy Alchemy - A library to load SQLAlchemy Tables Lazily\n\nAnd many more in progress ...\nDocker HUB\nRhinestone\nMedium Articles (Published in NerdForTech and MLearning.ai)\nhttps://vivek-keshore.medium.com\nGithub\nGithub\nLinkedIn\nLinkedIn\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7cdadd75-657a-4e85-89ca-26f08f3ffcae": {"__data__": {"id_": "7cdadd75-657a-4e85-89ca-26f08f3ffcae", "embedding": null, "metadata": {"Section": "Web & App development", "Type": "Workshops", "Target Audience": "Intermediate", "Last Updated": "14 Sep, 2023", "title": "Building Multi-Tenant applications with Django and Django-Tenants", "speaker": "Jatin Goel (~jatin15)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "86e96b6a794f4671fa4303b61c25ab520093c43d295e41a92ec1e61b4bc08aff", "text": "\n\nDescription:\nModern solutions require to be scalable and cater to the needs of different customers by keeping their data segregated.\nCome explore how we can build scalable solutions with Django and truly make a Multi-Tenant solution, different ways possible to achieve this and how we\u2019ve cracked that tough nut.\n\nBrief intro about myself\nTraditional systems\n\nOn-Prem\nIsolated deployments for each customer\n\nMulti-tenancy\n\nWhat it is?\nHow does it solve the above problem\nPros and Cons\nDifferent multi-tenancy approaches\n\nDjango tenants\n\nHow it works\nAll the different components of the library\n\n\nIn this workshop we'll go over:\n\nSetting up a Django project\nIntegrating Celery with regular Django project\nPostgres schemas\nConverting the single-tenant project to multi-tenant with Django-Tenants\nTypes of Multi-Tenancy\nCreating organisations and domains\nTenant Schema Router\nTenant Aware Celery App\nPeriodic tasks for each tenant\nDatabase Routers (Advanced) (if time permits)\n\nBy end of this workshop you should've the right information to know whether your app needs to be a MT app and how we manage\nthese multiple tenants\n\n\n\nPrerequisites:\n\nPython 3.11\nDjango 3.2\nDocker\nBasic Django knowledge\nBasic knowledge about async / distributed tasks\nKnowledge about django cookiecutter setup, so it's easier to navigate through the project structure\n\n\n\n\nSpeaker Links:\nhttps://www.linkedin.com/in/goeljatin/\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4c88a110-f1a8-4581-b06a-6934b9009d20": {"__data__": {"id_": "4c88a110-f1a8-4581-b06a-6934b9009d20", "embedding": null, "metadata": {"Section": "Data Science, AI & ML", "Type": "Workshops", "Target Audience": "Intermediate", "Last Updated": "22 Sep, 2023", "title": "Instruction Finetuning: Unlock the Power of Large Language Models", "speaker": "Abhijeet Kumar (~abhijeet3922)"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {}, "hash": "d2c0184455c59c60675b8ad259179daaedcda143e01a60580fbdf87cbd147519", "text": "\n\nDescription:\nLarge Language models (LLMs) are powerful tools that can be used for variety of tasks such as question answering, translation, content generation and other natural language understanding tasks. However, there are few challenges currently with open source LLMs trained on massive internet data. Two such reasons are:\n\nLLMs may not be accurate for complex tasks.\nLLMs may not have learnt nuances of specific domain well hence does not hold good for such in-domain tasks.\n\nThese issues can be resolved by better aligning LLMs by Instruction Finetuning techniques.\nWhy does it matter ?\nMany businesses or captive companies intends to owning their models, and create superior quality models for their domain specific applications without handing their sensitive data over to third parties.\nAgenda\nThe workshop will cover the mainly the following sections.\n1. Prompting LLMs (zero/few shot) \n2. Few-shot Finetuning LLMs\n3. Instruction Finetuning of LLMs\n\nThe workshop may be designed that includes both a tutorial on implementing Instruction Finetuning techniques and hands-on practice session where participants can apply the same on other tasks.\nWe will cover these section using HuggingFace and other useful libraries for the above agenda. Participants can use Google Collab to perform all the above tasks. For audience aware of LLMs, the workshop intends to demonstrate \"How to train your own Alpaca or Dolly models using Llama-2 models?\". I will begin by covering the basics of working with LLMs and some of few-shot finetuning techniques. I will then build on this foundation to demonstrate how to train replicable models like Alpaca, Dolly etc. with prompt-response pairs.\nAudience\nThis workshop is intended for any developers who are interested in finetuning LLMs for improved accuracy. No prior experience of Finetuning LLMs is required. \nBasic to Intermediate skillset should be fine.\nOutcomes\nBy the end of the workshop, participants will be able to:\n\nWorking with recent LLMs\nFinetune LLM using labelled examples.\nInstruction Finetuning of LLMs.\nPractical aspects of applications.\n\nMaterials\nThe workshop will provide participants with all the materials they need to complete the exercises. These materials will include a workshop notebooks, datasets and codes.\n\n\nTopics to be covered in the Workshop\n\n\n\nState of Finetuning (Talk)\nInferencing: Prompting LLMs for a task \n\nzero-shot\nfew-shot\n\nMemory requirements (Talk)\nFew Shot Finetuning using PEFT Techniques\n\nPEFT - Prompt Tuning\nPEFT - LORA\n\nPerformance comparison of Prompting vs Few shot Finetuning on two domain specific datasets.\n\nFinancial Phrasebank\nESG-Prospectus-Clarity-Category \n\nBuilding a Replication model (Talk)\nInstruction Finetuning on Sequence to Sequence Task\n\nSummarization Task: SAMSum dataset.\nQLoRa Finetuning: Train Dolly, Alpaca LLM using Llama-2 chat model\n\nKey Takeaways & Closing Talk\n\n\n\n\nPrerequisites:\n\nLaptop with internet connection.\nBasic knowledge of using Python in Machine Learning.\nUnderstanding of Large Language Model.\nFamiliarity with HuggingFace and Collab.\n\n\n\n\nContent URLs: \nAll notebooks and slides can be download from GitHub link here.\n\n\n\nSpeaker Info:\nI am an applied data scientist and research professional with 10+ years of relevant experience in solving problems leveraging advanced analytics, machine learning and deep learning techniques. I started my career as a Scientific Officer in a central government research organization (Bhabha Atomic Research Center) and worked on variety of domains such as conversational speech, satellite imagery and texts. Currently, I am working as a Director, Data Scientist with Fidelity investment for last 4 years working on language models (NLP) and Graphs.\nAs part of my work, I have used python throughout my career for solving data science problems as well as for pursuing research. I have published several academic and applied research papers and participated in multiple conferences over years. In past, I had trained professionals in machine learning and had been guest lecturer at BITS, Pilani, WILP program for Machine Learning subject (MTech course).\n\n\n\nSpeaker Links:\nBlog: https://appliedmachinelearning.wordpress.com/\nGithub: https://github.com/abhijeet3922\nLinkedln: https://www.linkedin.com/in/abhijeet-kumar-1aa8b0138/\nOpen Source Contributions:\n\nfinbert-embedding: https://pypi.org/project/finbert-embedding/\nclassitransformers: https://pypi.org/project/classitransformers/\nPhraseExtraction\n\n\n\n", "start_char_idx": null, "end_char_idx": null, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}}, "docstore/metadata": {"a67ac7a9-ff7d-4564-8680-7cd97318c105": {"doc_hash": "601a0e2a7ea5129035608f3e8d5d8495a274d9327c73c05c597ec4c446e1f321"}, "01bd0569-e9a1-4826-9941-4a97946c9576": {"doc_hash": "b0c8111dbac9a4867ef701705dbcc7da3d1ab5e701a6b7baef09aded41ed2bea"}, "89c72d08-a8b8-4b3a-a612-095bc14ec5db": {"doc_hash": "c72511ac7457e3cf3898809b021e7065d25821de72a959c87c74f1fa0475ebd2"}, "12e7972e-a0a0-4eb5-bd40-53214902f2fd": {"doc_hash": "390c1d48fc02712ed0361bdc24d4fa01d269703b0aa2c9d56c9e9eba7785f70d"}, "9ac92011-42cb-4180-af2c-5a6714082acc": {"doc_hash": "0f7acb9e77cbcbab910098c483dc0294ac4e7b7889d9a284e3f529e99657ff01"}, "906c31f0-3c77-4734-92a4-e021d33c90f9": {"doc_hash": "5d467a392e6058cd8e2f208fccd1a771c5522a9b66506fadb5265957ce30563c"}, "b77e7671-7eb9-473e-961a-eaff94e9d8d2": {"doc_hash": "9d0ece76166c4d3359b518a34441dcc80954ad1c6d5195ca255a7d1d18294248"}, "c6a835b2-6b3c-4573-be5b-e9ffe34bb693": {"doc_hash": "351eb1154c69af37896a943b6844fde51505b11602132c2cf701d1d9dad737fa"}, "62a3d4a8-fea9-402f-87ff-a76c584bae25": {"doc_hash": "c4016cd625d1b9ea4831901020a0d27e9bb27a60ee579fee2c8c7a23c2e6536c"}, "bd896639-527b-4fc2-aa5a-993720ef0fdd": {"doc_hash": "8029ef0bd1bbb61ba5e600b573188d302a61b09fb12e2ef82089b64dc16a37d8"}, "d1fbc296-aebf-405e-8264-2a18b5e5b526": {"doc_hash": "862146e7b45ac456bc613b25c2d1098cc1676157bfcbbcb9fb78cf7239602a92"}, "b497b710-57d2-4734-9a71-4da9dbddb623": {"doc_hash": "c2f845102c6e4e68fb0946c12afddd8bb8523af220d4b6657b498b19aa5adf5a"}, "27365734-0c7a-42e7-9167-801e27d34e83": {"doc_hash": "37f1321a810e4b68286ff1933e47d5bba4ca5dd1c9be822c61787d4d7dea6aba"}, "19a7161e-b375-45d6-bb3f-d31b8cbfbfa2": {"doc_hash": "e1baae958a5953772cf407394d3af53be492ec5aa26e114e024b11262574a35f"}, "969cd152-ee2f-42d6-a69b-256b29c0291c": {"doc_hash": "932a2fbbdb960c2ffcfe66a7c6190f1266d8847424ce0edfae28be11d0b8c405"}, "f62d01fa-6780-43ff-9550-9581f253b42d": {"doc_hash": "f9b327ff5ed49464f0219a0b1369b944a01c608a4bc9aa62ea57396be2283fc3"}, "2a8669b6-6c87-4bb9-a690-1f2413c4221b": {"doc_hash": "6019dc8ab86e99e5ff77cad2789348ff373f5d3fe5c182a29377bfa846a9d096"}, "f9a3090e-aa3f-4e2f-a10b-2c30db78083a": {"doc_hash": "2771069395a87149867d723abc7698ddf38b875d0f5ec2246d58ab540822eb35"}, "59cd531b-c008-478e-ac5f-7742b8a8939e": {"doc_hash": "427e0b27f30c2081e94a42f5b22411b49404b0720d06d575f5f21bd0426d658f"}, "5887efcc-a9c5-46c8-9c64-6f74a9eb36d2": {"doc_hash": "79cf299b6e57e2fe64e799348d21602d8bb17d4aa119f331cee552b81c48111d"}, "5080e8e8-1210-4954-9df4-9ae9f54a378c": {"doc_hash": "be4ef0d20c3bb2bb67f49c5eea57e6d42ed12ab3eab48f0e98cab9419dff481a"}, "2aeaa010-0714-4276-809f-29a6cfa1a133": {"doc_hash": "e5ccefa23a4cd175d3d09d60f6d9f921aa954090f5d52737b517471486ebd8ef"}, "3394821a-62b9-40e9-846d-39ca712fb7b2": {"doc_hash": "d8720e2b402cf13d6462553c34df3be8e6a7ce7a1f2049e0dc8697b6e00ea75c"}, "cea42dcc-7939-4ccd-b9b2-de1603402993": {"doc_hash": "5b3408a5b261a5956ec2abd91441aa85c25c027c3ab7a6be9d3ab3433b4a693c"}, "9f7656c2-1a46-4e32-94ae-c66f9636aee4": {"doc_hash": "8013eb718f95c2baaa9ed0e45c39720752a82a77d389675fb6208ccfdb4e7c5c"}, "46c3a357-f67e-4589-9a63-0221fd700bfc": {"doc_hash": "45dbb469a714005f070cc5fbf3c9a2d1ac3c72432b9eeda189794769e3dffe91"}, "1d3bbd13-f4c2-48e1-84bd-2d4f7cc5568f": {"doc_hash": "bb93469c97b971a5a94f82438e3f8fbc95c054cea24ec43a06bdb301ce280c83"}, "5cfad886-7f8f-4740-af16-7ea1797731d4": {"doc_hash": "99311aa7a960ef6704c8f02ecab2a727bfa976c6652b8cd2ad6881e31f0c89b5"}, "bb2fcb57-f81d-43a5-b626-3da620062520": {"doc_hash": "947d3626593a06e3d97b65befb4b3a44ed4c55a8325b769cf719e4aa68c58a2b"}, "16b41630-e798-4d98-b013-8860e7b0f31f": {"doc_hash": "c5279947aa390f1d9c6cc4a3fee25a61cb29323b903f7fc6509205a37a3fe070"}, "b19a6d8f-f55d-4cff-998a-944b9f0cac43": {"doc_hash": "5de859bbdde566c16dd52f22288a29e60ae7e2aa07c6d2512813cb043d4de475"}, "65df0eb8-704c-43b5-9f67-82cd3536d415": {"doc_hash": "7a7d537a756023e630f19101f84587976631858d440ceaadb9766c1000510c15"}, "4f296b2a-9a76-4d39-8bc2-c9aecd571c2d": {"doc_hash": "b860d4b535effe0d971d9bb4e7a341ad4aa26327962a321ab04d5f3488e98d1f"}, "65837819-e65f-49d4-8c11-190b152c4287": {"doc_hash": "898036824923c70d3c04831970b2fec821ebf9924a1dd00394d35ffa312582fd"}, "5aea78b6-7b3f-4330-90b5-d43bf067299d": {"doc_hash": "b4a55a334c9f5ff8215e5f279bc077d4c7e027681f0edddb14705bfe35f3e33d"}, "1e264a40-fe2f-4c0f-954b-32427f471b0a": {"doc_hash": "e14d7553deeccb8ea1d62416410198657cc8a709cd7f41f92b81101b1fea34fe"}, "8ba2c171-2221-40d8-ad8d-331cf9ecaa9f": {"doc_hash": "2d8324377fc9396b60d20890666da33fd3d214c6cae8594e7514ba448b7152c5"}, "aea2acc5-0108-488e-8153-35b886a8f53a": {"doc_hash": "eb9185da1d6b96a80eebe179bc1f6bf20f63da013e189e943da636ddd7b3af2b"}, "e32c921a-fdab-4579-a928-d5e8159d4a2f": {"doc_hash": "a099e4fe75a2ffd88f392343370573366cc0f1bfcf846264ac07c451ddfd17ee"}, "fcdd1f43-a1fa-49f9-8734-e5448d09fe34": {"doc_hash": "3aae90d1c4818898f5ab23f26425dd3c00d8117b756fabbc6a4ebaa726884c84"}, "7cdadd75-657a-4e85-89ca-26f08f3ffcae": {"doc_hash": "86e96b6a794f4671fa4303b61c25ab520093c43d295e41a92ec1e61b4bc08aff"}, "4c88a110-f1a8-4581-b06a-6934b9009d20": {"doc_hash": "d2c0184455c59c60675b8ad259179daaedcda143e01a60580fbdf87cbd147519"}}}